
================================================================================
QUANTUM DIAMOND FORGE - PROTOCOL v2.0 RED TEAM SNAPSHOT
Timestamp: 2025-11-23T01:45:17.970Z
Purpose: Independent analysis and review by external LLMs
================================================================================
Total Files: 37
--------------------------------------------------------------------------------

## Project Structure
```
GUIDE.md
INBOX/README.md
README.md
TASKS/done/001_harden-protocol-with-industry-benchmarks.md
diagrams/conceptual_overview.mermaid
diagrams/dependency_graph.mermaid
diagrams/sequence_diagram.mermaid
diagrams/workflow_map.mermaid
guides/cicd/git_workflow.md
guides/cicd/github_setup.md
guides/cicd/how_to_commit.md
guides/cicd/overview.md
guides/cicd/security_scanning.md
prompts/00_MASTER_PROTOCOL.md
prompts/00_MASTER_PROTOCOL_LEAN.md
prompts/01_requirements_analysis.md
prompts/02_architecture_design.md
prompts/03_security_compliance.md
prompts/04_testing_strategy.md
prompts/05_implementation_plan.md
prompts/REDTEAM/gpt5-response.md
prompts/REDTEAM/grok4-response.md
prompts/REDTEAM/redteam_analysis.md
prompts/REDTEAM/synthesis.md
prompts/lean/01_requirements_analysis.md
prompts/lean/02_architecture_design.md
prompts/lean/04_testing_strategy.md
prompts/lean/05_implementation_plan.md
prompts/lean/TEST_SCENARIO.md
prompts/modules/README.md
prompts/modules/architecture/c4_diagrams.md
prompts/modules/architecture/data_models.md
prompts/modules/requirements/feature_catalog.md
prompts/modules/requirements/product_overview.md
prompts/modules/requirements/user_stories.md
prompts/modules/security/threat_modeling.md
prompts/modules/testing/test_pyramid.md
```

## File: GUIDE.md
```md
# The Quantum Diamond Forge Guide

**Status:** v20 (The "Universal Base" Edition)
**Philosophy:** "Don't prompt the ocean; build the aqueduct."

---

## 1. Introduction: Beyond "Vibe Coding"

We live in the age of **"Vibe Coding"**‚Äîwhere a single prompt can generate a stunning, functional app in seconds. It's magical. It captures the *idea*.

**But what happens next?**

Most AI-generated apps are "Prototype Plus"‚Äîfunctional but fragile. They look great but often lack the rigor required for the real world:
*   **Security Gaps:** Missing rate limiting, weak input validation, permissive CORS.
*   **Operational Fragility:** No structured logging, basic health checks, no observability.
*   **Maintenance Nightmares:** Ad-hoc patterns, no testing strategy, no architectural documentation.

### The Antigravity Solution
The **Quantum Diamond Forge** is the answer to this fragility. Built upon the principles of the [Quantum Diamond Framework](https://medium.com/@rfremmer_30873/beyond-the-double-diamond-design-process-a-new-framework-for-the-ai-age-the-quantum-diamond-980fe3f89319), this protocol operationalizes "Rigour at Speed."

It is not just a set of prompts; it is a **Universal Base** for orchestrating multiple AI agents to build software that is **Secure by Design**, **Operationally Mature**, and **Production Ready** from Day 1.

It addresses the common critiques of AI code (like those found in an [Antigravity Audit](#)) by enforcing:
*   **Strict Contracts:** Zod schemas for every input.
*   **Defense in Depth:** Helmet, Rate Limiting, and RBAC baked in.
*   **Observability:** Structured logging with Correlation IDs.
*   **Testing Pyramids:** Unit, Integration, and E2E tests as first-class citizens.

---

## 2. The Mental Model

1.  **The General (You + Local Agent):** You operate *locally*, inside this repository.
2.  **The Specialists (Web AIs):** ChatGPT (o1/4o) and Gemini (1.5 Pro) are your high-IQ consultants for "Precision Strikes".
3.  **The Expert Council:** A library of specialized personas (Architect, DevOps, Security) you can summon for deep-dive tasks.
4.  **The Shared Brain (The Repo):** This repository is the source of truth. It comes pre-loaded with **Governance** (ADRs), **Task Management**, and **Validation Scripts**.

---

## 3. The Workflow

### Conceptual Overview
This is how the entire system works from a developer's perspective.

```mermaid
flowchart TB
    Start([Developer with Idea]) --> Clone[Clone Quantum Diamond Forge]
    Clone --> IDE[Open in Antigravity IDE]
    
    subgraph Orchestration ["üéØ Antigravity IDE (The Orchestrator)"]
        IDE --> Guide[Read GUIDE.md]
        Guide --> Loop{Walk Through Steps}
    end
    
    subgraph WebTools ["üåê External AI Tools (Precision Strikes)"]
        WebAI[ChatGPT/Claude<br/>Product & Architecture]
        Gemini[Google AI Studio<br/>Design & Scaffolding]
        Specialized[App Builder Tools<br/>Specialized Outputs]
    end
    
    subgraph LocalExecution ["üíª Local Project (Growing Rigor)"]
        Artifacts[Artifacts Folder<br/>PRODUCT_SPEC.md<br/>TECHNICAL_BLUEPRINT.md<br/>context.design.json]
        Scripts[Scripts & Validation<br/>validate_drift.ts<br/>Security Baseline]
        Code[Production Code<br/>With Tests & Docs]
    end
    
    subgraph ExpertCouncil ["üë• Expert Council (Role-Based Context)"]
        Architect[System Architect<br/>ADRs & Structure]
        Backend[Backend Developer<br/>APIs & Services]
        DevOps[DevOps Engineer<br/>CI/CD & Infra]
        QA[QA Engineer<br/>Test Strategy]
        Security[Security Auditor<br/>Threat Modeling]
    end
    
    %% Main Flow
    Loop -->|Step 1-2| WebAI
    Loop -->|Step 3-4| Gemini
    Loop -->|Optional| Specialized
    
    WebAI --> Artifacts
    Gemini --> Artifacts
    Specialized --> Artifacts
    
    Artifacts --> Scripts
    Scripts --> Code
    
    %% Expert Invocations (Dotted = Optional)
    Loop -.->|Deep Dive| ExpertCouncil
    ExpertCouncil -.-> Code
    
    %% IDE Orchestration
    IDE -->|Infinite Context| Code
    IDE -->|Quality Gates| Scripts
    IDE -->|Drift Prevention| Artifacts
    
    %% Final Output
    Code --> Done([Production-Ready Application])
    
    style IDE fill:#dcfce7,stroke:#166534,stroke-width:3px
    style Done fill:#fef3c7,stroke:#d97706,stroke-width:3px
    style Artifacts fill:#dbeafe,stroke:#1e40af,stroke-width:2px
```

### High-Level Flow
This diagram shows the artifact generation pipeline and how the Expert Council integrates.

```mermaid
---
config:
  layout: dagre
---
flowchart LR
    User([üë§ You]) -->|1. Clone & Open| IDE[üéØ Antigravity IDE]
    
    IDE -->|2. Kickoff Prompt| Kickoff[üöÄ Phase 0: Kickoff<br/>Gemini 1.5 Pro]
    
    Kickoff -->|Guides User| WebAI[üåê Web AI<br/>ChatGPT/Claude/Grok/Gemini]
    
    WebAI -->|Generates| Artifacts[üì¶ Artifacts<br/>Specs, Blueprints,<br/>Design, Scripts]
    
    WebAI -.->|Deep Dive Prompts| Experts[üë• Expert Council<br/>Architect, DevOps,<br/>QA, Security]
    
    Artifacts -.->|Optional Deep Dive| Experts
    
    Artifacts --> IDE
    Experts -.-> IDE
    
    IDE -->|3. Build & Validate| Code[üíª Production Code]
    
    Code -->|Drift Check| Validate{‚úì Quality Gates}
    
    Validate -->|Pass| Done([‚úÖ Production Ready])
    Validate -->|Fail| IDE
    
    Done --> User
    
    style Artifacts fill:#dbeafe,stroke:#1e40af,stroke-width:2px
    style Done fill:#dcfce7,stroke:#166534,stroke-width:2px
    style IDE fill:#fef3c7,stroke:#d97706,stroke-width:2px
    style Kickoff fill:#e0e7ff,stroke:#3730a3,stroke-width:2px
```

### Detailed Sequence
This diagram shows the exact step-by-step interaction between you, the CLI, and the AIs.

```mermaid
sequenceDiagram
    autonumber
    actor User
    participant CLI as Forge CLI
    participant WebAI as Web AI (ChatGPT/Gemini)
    participant Repo as Local Repo (Artifacts)
    participant Agent as Local IDE Agent

    Note over User, Repo: Phase 0: Initialization
    User->>CLI: ./forge.sh init
    CLI-->>Repo: Creates Project Structure
    User->>CLI: ./forge.sh prompt 0
    User->>WebAI: Paste Kickoff Prompt
    WebAI-->>User: Strategic Roadmap

    Note over User, WebAI: Phase 1: Product Spec
    User->>CLI: ./forge.sh prompt 1
    User->>WebAI: Paste Prompt 1 + Idea
    WebAI-->>User: Generates PRODUCT_SPEC.md
    User->>Repo: Save PRODUCT_SPEC.md

    Note over User, WebAI: Phase 2: Tech Blueprint
    User->>CLI: ./forge.sh prompt 2
    User->>WebAI: Paste Prompt 2 + PRODUCT_SPEC
    WebAI-->>User: Generates TECHNICAL_BLUEPRINT.md
    User->>Repo: Save TECHNICAL_BLUEPRINT.md

    Note over User, WebAI: Phase 3: Design System
    User->>CLI: ./forge.sh prompt 3
    User->>WebAI: Paste Prompt 3 + Artifacts
    WebAI-->>User: Generates context.design.json
    User->>Repo: Save context.design.json

    Note over User, WebAI: Phase 4: Scaffolding
    User->>CLI: ./forge.sh prompt 4
    User->>WebAI: Paste Prompt 4 + Artifacts
    WebAI-->>User: Generates setup.sh
    User->>Repo: Run setup.sh (Generates Security/Drift)

    Note over User, Agent: Phase 5: Execution (Antigravity)
    User->>CLI: ./forge.sh prompt 5
    User->>Agent: Paste System Prompt
    loop Antigravity Loop
        User->>Agent: Assign Task (from Backlog)
        Agent->>Repo: Read Artifacts (Blueprint/Design)
        Agent->>Repo: Write Code
        Agent->>Repo: Run validate:drift
        Repo-->>Agent: Pass/Fail
    end
```

---

## 4. The Protocol Steps

### Step 0: Kickoff (The "Strategy")
**[üëâ View Guide](guides/00_kickoff.md)**
*   **Goal:** Initialize strategy and get a personalized roadmap.
*   **Action:** Run `./forge.sh start` -> Paste to Gemini 1.5 Pro.
    *   *Note:* This launches the **Interactive Antigravity Guide**, which will interview you about your idea and create a tailored plan.

### Step 1: Product Specification (The "What")
**[üëâ View Guide](guides/01_product_spec.md)**
*   **Goal:** Define the Narrative, Audience, and Core Features.
*   **Action:** Run `./forge.sh prompt 1` -> Paste to ChatGPT -> Save `PRODUCT_SPEC.md`.

### Step 2: Technical Blueprint (The "How")
**[üëâ View Guide](guides/02_tech_blueprint.md)**
*   **Goal:** Define the Architecture, Stack, and Security.
*   **Action:** Run `./forge.sh prompt 2` -> Paste to ChatGPT (with Spec) -> Save `TECHNICAL_BLUEPRINT.md`.

### Step 3: Design System (The "Look")
*   **Goal:** Define the Visual Language.
*   **Action:** Run `./forge.sh prompt 3` -> Paste to Gemini (with Spec) -> Save `context.design.json`.

### Step 4: Scaffolding (The "Build")
*   **Goal:** Create the secure habitat.
*   **Action:** Run `./forge.sh prompt 4` -> Paste to Gemini (with Blueprint + Design) -> Save & Run `setup.sh`.

### Step 5: Execution (The "Loop")
*   **Goal:** Build features.
*   **Action:** Run `./forge.sh prompt 5` -> Paste to IDE Agent -> Drag in Tasks.

---

## 5. Project Management Tools (Built-in)

The Forge comes with local tools to manage your project's governance.

### Tasks
Manage your backlog with structured markdown files.
```bash
./forge.sh task "Implement User Auth"
# Creates TASKS/backlog/001_implement_user_auth.md
```

### ADRs (Architectural Decision Records)
Document your technical decisions.
```bash
./forge.sh adr "Use Supabase for Auth"
# Creates docs/adr/0001-use-supabase-for-auth.md
```

### Code Snapshots
Capture your codebase context for the Expert Council.
```bash
# Capture everything (default)
./forge.sh snap output.txt

# Capture only code files (great for LLM context)
./forge.sh snap code_only.txt --mode code

# Capture specific folders (e.g., for a specific feature)
./forge.sh snap feature_context.txt --folders src/components,src/hooks
```

### Git Hooks (Automated Guardrails)
The Forge installs pre-configured Git hooks to keep your repo clean.
*   **Pre-commit:**
    *   Prevents commits to `main` branch.
    *   Blocks large files (>50MB).
    *   Runs `validate_drift.ts` (if present) to ensure code matches blueprint.
*   **Commit-msg:**
    *   Enforces [Conventional Commits](https://www.conventionalcommits.org/) (e.g., `feat: add login`).

### CI/CD & Workflow Guides
Detailed guides for setting up your pipeline and mastering the git workflow.
*   **[CI/CD Overview](guides/cicd/overview.md):** The big picture of how code moves from laptop to production.
*   **[GitHub Setup](guides/cicd/github_setup.md):** How to configure your repo for security and automation.
*   **[Git Workflow](guides/cicd/git_workflow.md):** Quick reference for branches, aliases, and commands.
*   **[How to Commit](guides/cicd/how_to_commit.md):** Step-by-step guide to passing the pre-commit hooks.
*   **[Security Scanning](guides/cicd/security_scanning.md):** Understanding and fixing vulnerability alerts.

### The Inbox Workflow
The `INBOX/` folder is your "Drop Zone" for AI collaboration.
1.  **Drop:** Drag messy notes, drafts, or external docs into `INBOX/`.
2.  **Prompt:** Tell the Agent "Check the Inbox."
3.  **Process:** The Agent will refactor, format, and move the files to their correct location (e.g., `docs/`, `TASKS/`).

---

## 6. The Expert Council (Specialized Roles)

Use these roles when you need deep expertise in a specific domain.

### How to Use
Run `./forge.sh role <role_name>` to copy the prompt.

*   **System Architect** (`architect`): Use for defining directory structures, ADRs, and technical constraints.
*   **Backend Developer** (`backend`): Use for implementing complex API logic, database schemas, and microservices.
*   **DevOps Engineer** (`devops`): Use for setting up CI/CD pipelines, Dockerfiles, and Infrastructure as Code.
*   **QA Engineer** (`qa`): Use for defining test strategies and writing E2E test suites.
*   **Security Auditor** (`security`): Use for threat modeling and security reviews.

---

## 7. Repository Deep Dive

*   `forge.sh`: The CLI tool.
*   `prompts/`: Core protocol prompts.
    *   `roles/`: The Expert Council prompts.
*   `guides/`: Detailed sub-guides.
*   `scripts/`: Automation tools (`new_task.sh`, `new_adr.sh`, `capture_snapshot.js`).
*   `templates/`: Source templates for artifacts.
*   `TASKS/`: Your project backlog.
*   `docs/adr/`: Your decision log.

```

## File: INBOX/README.md
```md
# Inbox

**Drop Zone for AI Processing**

Place any drafts, notes, or external documents here that you want the Antigravity Agent to review, refactor, or integrate into the project.

**Workflow:**
1. Drag files here.
2. Tell the Agent: "Check the Inbox."
3. The Agent will process them and move them to their permanent home (e.g., `docs/`, `TASKS/`).

```

## File: README.md
```md
# Quantum Diamond Forge üíé

**The Universal Base for AI-Native Development.**

[![CI](https://github.com/richfrem/quantum-diamond-forge/actions/workflows/ci.yml/badge.svg)](https://github.com/richfrem/quantum-diamond-forge/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> "Don't prompt the ocean; build the aqueduct."

The **Quantum Diamond Forge** is a protocol and scaffolding engine designed to operationalize "Rigour at Speed." It orchestrates AI agents (ChatGPT, Gemini, Claude) to build software that is **Secure by Design**, **Operationally Mature**, and **Production Ready** from Day 1.

## üöÄ Why?

Most AI-generated code is "Prototype Plus"‚Äîfunctional but fragile. It lacks:
*   **Security:** Rate limiting, input validation, headers.
*   **Ops:** Logging, health checks, Dockerfiles.
*   **Structure:** Consistent architecture and testing patterns.

The Forge solves this by providing a **Universal Base** of prompts, templates, and validation scripts that enforce quality gates at every step.

## üõ†Ô∏è Features

*   **Protocol-Driven Workflow:** A 5-step granular process (Spec ‚Üí Blueprint ‚Üí Design ‚Üí Scaffold ‚Üí Code).
*   **Expert Council:** Specialized AI personas (Architect, DevOps, Security) for deep-dive tasks.
*   **Automated Governance:** Built-in ADRs, Task Management, and Git Hooks.
*   **Defense in Depth:** Pre-configured security headers, Zod validation, and drift detection.

## ‚ö° Quick Start: Protocol v2.1

The Forge offers **two tracks** to match your project needs:

### üèÉ Lean Mode (Solo Devs & MVPs)
**Best for**: Prototypes, MVPs, solo developers, small teams

- **Time to Spec**: ~1 hour
- **Artifacts**: ~10 docs
- **Focus**: Essential features only
- **Start here**: `prompts/00_MASTER_PROTOCOL_LEAN.md`

### üè¢ Enterprise Mode (Production Apps)
**Best for**: Production apps, teams, compliance-heavy projects

- **Time to Spec**: ~4-6 hours
- **Artifacts**: 25+ docs
- **Focus**: Full rigor (C4 Level 1-3, STRIDE, compliance)
- **Start here**: `prompts/00_MASTER_PROTOCOL.md`

---

### The Workflow (Both Modes)
```mermaid
graph TD
    User["üë§ You (Orchestrator)"] -->|1. Idea| WebLLM["üß† Web LLM (Gemini/Claude)"]
    WebLLM -->|2. Generates| Specs["üìÑ Rigorous Specs (docs/)"]
    Specs -->|3. Guides| Agent["ü§ñ Antigravity Agent (IDE)"]
    Agent -->|4. Builds| Code["üíª Production Code"]
    
    subgraph "Phase 1: Specification Loop"
    WebLLM
    Specs
    end
    
    subgraph "Phase 2: Build Loop"
    Agent
    Code
    end
```

### Step-by-Step

1.  **Clone the Forge:**
    ```bash
    git clone https://github.com/richfrem/quantum-diamond-forge.git
    cd quantum-diamond-forge
    ```

2.  **Start the Master Protocol:**
    Open `prompts/00_MASTER_PROTOCOL.md`. This is your command center.

3.  **Phase 1: The Specification Loop**
    Follow the guide to generate your "Gold Standard" documentation suite:
    *   `01_REQUIREMENTS.md` (Feature Catalog)
    *   `02_ARCHITECTURE.md` (C4 Diagrams)
    *   `03_SECURITY.md` (Threat Models)
    *   `04_TESTING.md` (Test Strategy)
    *   `05_IMPLEMENTATION.md` (Task Plan)

4.  **Phase 2: The Build Loop**
    Point your IDE Agent to the generated `task.md` and watch it build!

## üìö Documentation

*   **[The Guide (Start Here)](GUIDE.md)**: The complete manual for the protocol.
*   **[CI/CD & Workflow](guides/cicd/overview.md)**: How to ship code securely.
*   **[Expert Roles](prompts/roles/)**: Browse the specialized personas.

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## üìÑ License

This project is licensed under the [MIT License](LICENSE).

```

## File: TASKS/done/001_harden-protocol-with-industry-benchmarks.md
```md
# Task: Harden Protocol with Industry Benchmarks

**Status**: Done
**Created**: 2025-11-22
**Owner**: Antigravity

### Phase 2: Prompt Engineering
- [x] Create `prompts/01_requirements_analysis.md`
- [x] Create `prompts/02_architecture_design.md`
- [x] Create `prompts/03_security_compliance.md`
- [x] Create `prompts/04_testing_strategy.md`
- [x] Create `prompts/05_implementation_plan.md`
- [x] Remove legacy prompts (`01_product_spec.md`, etc.)
- [x] Create `prompts/00_MASTER_PROTOCOL.md` (The Guide)
- [x] Remove legacy kickoff files (`00_kickoff.md`, `00_interactive_kickoff.md`)
- [x] Update `README.md` with Protocol v2.0 workflow & Mermaid diagram
- [x] Update `README.md` with Protocol v2.0 workflow & Mermaid diagram
- [x] Refine `prompts/00_MASTER_PROTOCOL.md` to clarify Orchestrator role
- [x] Update `diagrams/workflow_map.mermaid`
- [x] Update `diagrams/conceptual_overview.mermaid`
- [x] Update `diagrams/sequence_diagram.mermaid`
- [x] Update `diagrams/dependency_graph.mermaid`

## Context
We analyzed enterprise-grade technical specifications (e.g., the "Helix" spec) to benchmark the Quantum Diamond Forge (QDF) protocol. The goal is to elevate QDF from generating "MVP-style" outputs to "Enterprise-Grade" specifications.

## Benchmark Analysis & Gap Report
The industry benchmark specs demonstrated superior rigor in several areas where QDF v1 was lacking:

| Area | Industry Benchmark (Helix Spec) | QDF v1 (Old Prompts) | Gap |
|------|---------------------------------|----------------------|-----|
| **Requirements** | Detailed Feature Catalog, MoSCoW, Functional/Non-Functional Requirements, Traceability Matrix. | Simple "Narrative" and "Core Feature Scope". | **High**: QDF lacked structured requirement definitions and traceability. |
| **Architecture** | C4 Diagrams, Event Flows, Detailed Component interactions. | High-level stack list and basic "Domain Architecture". | **Medium**: QDF needed standard diagramming (C4) and deeper API design. |
| **Security** | Explicit Threat Modeling, Compliance Controls (DSCSA, GDPR), AuthZ matrix. | "Shift Left" bullet points, generic security headers. | **Critical**: QDF lacked specific threat modeling and compliance mapping. |
| **Testing** | Test Pyramid, Performance criteria, Security testing (SAST/DAST). | Basic "CI/CD Pipeline" steps. | **High**: QDF missed a dedicated testing strategy. |

## Objective
Upgrade QDF to **Protocol v2.0** by implementing a rigorous 5-step prompting strategy that mimics enterprise depth.

## Implementation Checklist

### Phase 1: Protocol Design (v2.0)
- [x] **Analyze Benchmarks**: Extract patterns for Requirements, Architecture, and Security.
- [x] **Design New Prompt Architecture**:
    - `01_requirements_analysis.md`: Feature Catalog, User Stories.
    - `02_architecture_design.md`: C4, API, Data Models.
    - `03_security_compliance.md`: Threat Modeling, Compliance.
    - `04_testing_strategy.md`: Test Pyramid, Performance.
    - `05_implementation_plan.md`: Task Breakdown.

```

## File: diagrams/conceptual_overview.mermaid
```mermaid
flowchart TB
    Start([Developer with Idea]) --> Clone[Clone Quantum Diamond Forge]
    Clone --> IDE[Open in Antigravity IDE]
    
    subgraph Orchestration ["üéØ Orchestration (Human-in-the-Loop)"]
        IDE --> Master[Read 00_MASTER_PROTOCOL.md]
        Master --> Loop{Specification Loop}
    end
    
    subgraph WebTools ["üß† Web LLM (The Heavy Lifter)"]
        Gemini[Gemini 1.5 Pro / Claude 3.5<br/>Generates Enterprise Specs]
    end
    
    subgraph LocalExecution ["üíª Local Project (The Build)"]
        Artifacts[docs/ Folder<br/>1. Requirements<br/>2. Architecture<br/>3. Security<br/>4. Testing<br/>5. Implementation]
        Agent[Antigravity Agent<br/>(The Builder)]
        Code[Production Code]
    end
    
    %% Main Flow
    Loop -->|1. Copy Prompts| Gemini
    Gemini -->|2. Generate Docs| Artifacts
    
    Artifacts -->|3. Guide| Agent
    Agent -->|4. Write| Code
    
    %% Feedback Loops
    Code -.->|Verify| Agent
    Agent -.->|Refine| Artifacts
    
    %% Final Output
    Code --> Done([Production-Ready Application])
    
    style IDE fill:#dcfce7,stroke:#166534,stroke-width:3px
    style Done fill:#fef3c7,stroke:#d97706,stroke-width:3px
    style Artifacts fill:#dbeafe,stroke:#1e40af,stroke-width:2px

```

## File: diagrams/dependency_graph.mermaid
```mermaid
graph TD
    Req[01_REQUIREMENTS.md<br/>(Feature Catalog)] --> Arch[02_ARCHITECTURE.md<br/>(C4 & Data Models)]
    
    Req --> Sec[03_SECURITY.md<br/>(Threat Models)]
    Arch --> Sec
    
    Req --> Test[04_TESTING.md<br/>(Test Strategy)]
    Arch --> Test
    
    Req --> Plan[05_IMPLEMENTATION.md<br/>(Task Breakdown)]
    Arch --> Plan
    Sec --> Plan
    Test --> Plan
    
    style Req fill:#dbeafe,stroke:#1e40af,stroke-width:2px
    style Plan fill:#dcfce7,stroke:#166534,stroke-width:2px

```

## File: diagrams/sequence_diagram.mermaid
```mermaid
sequenceDiagram
    autonumber
    actor User as üë§ You (Orchestrator)
    participant Master as üìú Master Protocol
    participant WebAI as üß† Web LLM (Gemini/Claude)
    participant Repo as üìÇ Local Repo (docs/)
    participant Agent as ü§ñ Antigravity Agent

    Note over User, Repo: Phase 1: The Specification Loop
    
    User->>Master: Read Step 1 (Requirements)
    User->>WebAI: Paste Prompt 01 + Idea
    WebAI-->>User: Generates Feature Catalog
    User->>Repo: Save docs/01_REQUIREMENTS.md
    
    User->>Master: Read Step 2 (Architecture)
    User->>WebAI: Paste Prompt 02 + Requirements
    WebAI-->>User: Generates C4 Diagrams
    User->>Repo: Save docs/02_ARCHITECTURE.md
    
    User->>Master: Read Step 3 (Security)
    User->>WebAI: Paste Prompt 03 + Context
    WebAI-->>User: Generates Threat Model
    User->>Repo: Save docs/03_SECURITY.md
    
    User->>Master: Read Step 4 (Testing)
    User->>WebAI: Paste Prompt 04 + Context
    WebAI-->>User: Generates Test Strategy
    User->>Repo: Save docs/04_TESTING.md
    
    User->>Master: Read Step 5 (Plan)
    User->>WebAI: Paste Prompt 05 + Context
    WebAI-->>User: Generates Implementation Plan
    User->>Repo: Save docs/05_IMPLEMENTATION.md
    
    Note over User, Agent: Phase 2: The Build Loop
    
    User->>Agent: Point to docs/05_IMPLEMENTATION.md
    loop Antigravity Build Cycle
        Agent->>Repo: Read Specs
        Agent->>Repo: Write Code
        Agent->>Repo: Run Tests
        Repo-->>Agent: Pass/Fail
    end

```

## File: diagrams/workflow_map.mermaid
```mermaid
---
config:
  layout: dagre
---
flowchart LR
    User([üë§ You (Orchestrator)]) -->|1. Open| Master[üìú Master Protocol]
    
    Master -->|2. Copy Prompts| WebAI[üß† Web LLM<br/>Gemini 1.5 Pro / Claude 3.5]
    
    WebAI -->|3. Generates| Docs[üìÇ docs/<br/>1. Requirements<br/>2. Architecture<br/>3. Security<br/>4. Testing<br/>5. Plan]
    
    Docs -->|4. Guides| Agent[ü§ñ Antigravity Agent<br/>(IDE)]
    
    Agent -->|5. Builds| Code[üíª Production Code]
    
    Code -->|Verify| Validate{‚úì Quality Gates}
    
    Validate -->|Pass| Done([‚úÖ Production Ready])
    Validate -->|Fail| Agent
    
    style Docs fill:#dbeafe,stroke:#1e40af,stroke-width:2px
    style Done fill:#dcfce7,stroke:#166534,stroke-width:2px
    style Agent fill:#fef3c7,stroke:#d97706,stroke-width:2px
    style Master fill:#e0e7ff,stroke:#3730a3,stroke-width:2px

```

## File: guides/cicd/git_workflow.md
```md
# Git Workflow Quick Reference

This guide provides recommended git workflows and shortcuts for the quantum-diamond-forge project.

## TL;DR - Recommended Setup

```bash
# 1. Add these aliases to your ~/.gitconfig
git config --global alias.st "status -sb"
git config --global alias.aa "add --all"
git config --global alias.cm "commit -m"
git config --global alias.lg "log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit"

# 2. Use conventional commits (see examples below)

# 3. Let pre-commit hooks validate your changes
```

## Conventional Commit Format

```
<type>(<scope>): <subject>

<body>

<footer>
```

### Commit Types

| Type | When to Use | Example |
|------|-------------|---------|
| `feat` | New feature | `feat(auth): add OAuth2 login` |
| `fix` | Bug fix | `fix(api): handle null user response` |
| `docs` | Documentation only | `docs(readme): update setup instructions` |
| `style` | Code formatting (no logic change) | `style(components): fix indentation` |
| `refactor` | Code restructuring | `refactor(utils): extract validation logic` |
| `test` | Adding/updating tests | `test(api): add integration tests` |
| `chore` | Maintenance tasks | `chore(deps): update dependencies` |
| `ci` | CI/CD changes | `ci(github): add CodeQL workflow` |
| `perf` | Performance improvements | `perf(db): optimize query performance` |
| `revert` | Revert previous commit | `revert: revert feat(auth) commit` |

## Common Workflows

### 1. Feature Development (Standard)

```bash
# Create feature branch
git checkout -b feature/add-security-scanning

# Make changes, then stage specific files
git add .github/dependabot.yml
git add .github/workflows/codeql.yml
git add docs/ci-cd/README.md

# Review what you're about to commit
git diff --cached

# Commit with conventional format
git commit -m "feat(security): configure GitHub Advanced Security

- Add Dependabot for dependency scanning
- Add CodeQL for security analysis
- Update CI/CD docs with security guide

Refs: TASK-0067, ADR-040"

# Push to remote
git push origin feature/add-security-scanning

# Create PR on GitHub
# After PR approval, merge via GitHub UI
```

### 2. Quick Fix (Using Aliases)

```bash
# Fix a typo in documentation
git aa  # Stage all changes
git cm "docs(readme): fix typo in installation steps"
git push
```

### 3. Multi-file Changes (Interactive Staging)

```bash
# Stage specific lines from files
git add -p

# Review staged changes
git diff --cached

# Commit
git commit -m "refactor(api): extract error handling logic"

# Push
git push
```

### 4. Amend Last Commit

```bash
# Forgot to add a file to last commit
git add forgotten-file.js
git commit --amend --no-edit

# Or change the commit message
git commit --amend -m "feat(auth): add OAuth2 login (updated message)"

# Force push (only if not yet merged!)
git push --force-with-lease
```

## Useful Git Aliases

Add these to your `~/.gitconfig`:

```gitconfig
[alias]
    # Quick status
    st = status -sb

    # Stage all changes
    aa = add --all

    # Commit with message
    cm = commit -m

    # Amend last commit
    amend = commit --amend --no-edit

    # Pretty log
    lg = log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit

    # Show staged changes
    staged = diff --cached

    # Undo last commit (keep changes)
    undo = reset HEAD~1

    # List branches sorted by last modified
    branches = branch --sort=-committerdate

    # Show files in last commit
    last = show --name-only
```

## Pre-commit Hook Usage

Our pre-commit hook (`.githooks/pre-commit`) automatically validates:
- ‚úÖ No `.env` files (except `.env.example`)
- ‚úÖ No hardcoded secrets (API keys, tokens, passwords)
- ‚úÖ Blocks commit if violations found

**If the hook blocks your commit:**

```bash
# Review the violation
# Fix the issue (remove secret, use environment variable)
# Try committing again

# ONLY bypass if you're absolutely sure it's safe
git commit --no-verify -m "your message"
```

**‚ö†Ô∏è WARNING:** Never use `--no-verify` to bypass secret detection!

## Branch Naming Conventions

```
feature/short-description    # New features
fix/bug-description          # Bug fixes
docs/documentation-update    # Documentation
refactor/code-improvement    # Code refactoring
test/add-tests              # Test additions
chore/maintenance-task      # Maintenance
```

**Examples:**
- `feature/github-security-scanning`
- `fix/null-pointer-in-auth`
- `docs/update-ci-cd-guide`
- `refactor/extract-validation-logic`

## Commit Message Examples

### Good Commit Messages ‚úÖ

```bash
# Feature with detailed body
git commit -m "feat(security): add Dependabot and CodeQL workflows

- Configure Dependabot for npm and GitHub Actions
- Add CodeQL workflow for JavaScript/TypeScript analysis
- Update CI/CD documentation with security scanning guide

This implements the security scanning layer documented in ADR-040.

Refs: TASK-0067, ADR-040"

# Bug fix with issue reference
git commit -m "fix(auth): handle null user response from Supabase

Fixes #123"

# Documentation update
git commit -m "docs(ci-cd): add security scanning interpretation guide"

# Dependency update
git commit -m "chore(deps): bump axios from 0.21.1 to 1.6.0

Fixes CVE-2023-45857 (High severity)"
```

### Bad Commit Messages ‚ùå

```bash
# Too vague
git commit -m "fix stuff"
git commit -m "update files"
git commit -m "changes"

# No type prefix
git commit -m "added security scanning"

# Too long subject line (>72 chars)
git commit -m "feat(security): add Dependabot and CodeQL workflows for automated dependency scanning and security analysis"
```

## IDE Git Integration

### Visual Studio Code

1. **Stage files:** Click `+` next to file in Source Control panel
2. **Review changes:** Click file to see diff
3. **Commit:** Type message in input box, press `Ctrl+Enter`
4. **Push:** Click `...` ‚Üí Push

**Recommended extensions:**
- GitLens - Enhanced git capabilities
- Git Graph - Visualize branch history

### JetBrains IDEs (WebStorm, IntelliJ)

1. **Commit:** `Ctrl+K` (Windows/Linux) or `Cmd+K` (Mac)
2. **Review changes:** Check boxes for files to stage
3. **Commit message:** Type in message box
4. **Commit and Push:** Click dropdown ‚Üí Commit and Push

## Troubleshooting

### Pre-commit hook not running

```bash
# Make hook executable
chmod +x .githooks/pre-commit

# Verify git hooks path
git config core.hooksPath .githooks
```

### Accidentally committed secret

```bash
# 1. IMMEDIATELY revoke the secret in the service provider
# 2. Remove from git history
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch path/to/file" \
  --prune-empty --tag-name-filter cat -- --all

# 3. Force push (‚ö†Ô∏è coordinate with team!)
git push origin --force --all

# 4. Update environment variables with new secret
```

### Merge conflict

```bash
# 1. Pull latest changes
git pull origin main

# 2. Resolve conflicts in your editor
# Look for <<<<<<< HEAD markers

# 3. Stage resolved files
git add resolved-file.js

# 4. Complete merge
git commit -m "merge: resolve conflicts with main"

# 5. Push
git push
```

## Best Practices

1. **Commit often** - Small, focused commits are easier to review and revert
2. **Write clear messages** - Future you will thank present you
3. **Review before committing** - Always run `git diff --cached`
4. **Test before pushing** - Run `npm run lint` and `npm run test:unit`
5. **Pull before pushing** - Avoid merge conflicts
6. **Use branches** - Never commit directly to `main`
7. **Keep commits atomic** - One logical change per commit

## References

- [Conventional Commits](https://www.conventionalcommits.org/)
- [Git Documentation](https://git-scm.com/doc)
- [GitHub Flow](https://docs.github.com/en/get-started/quickstart/github-flow)
- ADR-041: Git Workflow Automation Strategy

```

## File: guides/cicd/github_setup.md
```md
# GitHub Repository Configuration Guide

This guide documents how to configure the **Quantum Diamond Forge** GitHub repository to enable CI/CD pipelines, security scanning, and automated workflows.

## Prerequisites

- Admin access to the GitHub repository
- Repository: `https://github.com/richfrem/quantum-diamond-forge`

## Best Practices for AI-Assisted Development

**‚ö†Ô∏è Important for Antigravity IDE Agents:**

When working with CI/CD pipelines that include security scans (CodeQL, Dependabot), follow these practices to minimize overhead:

1. **Batch commits locally** - Make multiple commits on your feature branch before pushing
2. **Push once when ready** - Only push when the feature is complete and tested locally
3. **Use draft PRs** - Mark PRs as "Draft" while still working, convert to "Ready for review" when done
4. **Avoid rapid push cycles** - CI scans (especially CodeQL) can take 1-2 minutes per run

**Why:** Security scans are resource-intensive. Pushing every small change creates unnecessary CI runs and slows down the development workflow.

**Recommended workflow:**
```bash
# Make multiple commits locally
git commit -m "feat: add feature part 1"
git commit -m "feat: add feature part 2"
git commit -m "fix: address edge case"

# Push once when ready
git push origin feature/my-feature

# Create PR (mark as draft if still WIP)
gh pr create --draft --title "WIP: My Feature"
```

## Step 1: Enable GitHub Actions (done)

GitHub Actions should be enabled by default, but verify:

1. Go to **Settings** ‚Üí **Actions** ‚Üí **General**
2. Under "Actions permissions", select:
   - ‚úÖ **Allow all actions and reusable workflows**
3. Under "Workflow permissions", select:
   - ‚úÖ **Read and write permissions**
   - ‚úÖ **Allow GitHub Actions to create and approve pull requests**
4. Click **Save**

## Step 2: Enable Security Features

1. Go to **Settings** ‚Üí **Code security and analysis** (Sidebar under "Security").
2. Under the **Advanced Security** section, **Enable** the following:
   - **Dependency graph** (Should be enabled by default)
   - **Dependabot alerts**
   - **Dependabot security updates**
     - *Optional:* Enable **Grouped security updates** to reduce noise.
   - **Secret Protection** -> **Push protection** (Block commits that contain supported secrets).
   - **Private vulnerability reporting** (Optional).

## Step 3: Configure CodeQL Analysis

**Eligibility:**
- **Public repositories:** Free for everyone.
- **Private repositories:** Requires GitHub Advanced Security (GHAS) license.

**Setup Instructions:**
1. Still in **Code security and analysis**, scroll down to **Code scanning** / **CodeQL analysis**.
2. Click **Set up** (or "Configure").
3. Choose **Default** setup (Recommended).
   - GitHub will automatically detect languages (JavaScript/TypeScript, Python, etc.).
   - It will create a dynamic workflow without you needing to commit a YAML file.
   - Click **Enable CodeQL**.

*(If "Default" is not available, choose "Advanced" and it will generate a `codeql.yml` file for you to commit).*

## Step 4: Create Development Branch

Before setting up branch protection, create a `dev` branch for integration testing:

```bash
# Make sure you're on main and up to date
git checkout main
git pull origin main

# Create dev branch from main
git checkout -b dev
git push -u origin dev

# Return to your working branch
git checkout -
```

## Step 5: Configure Branch Protection Rules

### 5.1 Protect the `main` Branch

1. Go to **Settings** ‚Üí **Branches**
2. Click **Add branch protection rule**
3. **Branch name pattern:** `main`
4. Enable:
   - ‚úÖ **Require a pull request before merging**
   - ‚ùå **Require approvals** - UNCHECK (not needed for solo dev, check for teams)
   - ‚úÖ **Require status checks to pass before merging**
     - ‚úÖ **Require branches to be up to date before merging**
     - **Add required status checks:**
       - `Test CLI Init` (from CI Pipeline)
       - `Shellcheck` (from CI Pipeline)
   - ‚úÖ **Require conversation resolution before merging** (optional but good practice)
   - ‚úÖ **Do not allow bypassing the above settings**
5. Click **Create**

**Result:** All changes to `main` must:
- Come from `dev` via PR
- Pass CI pipeline (linting, tests)

### 5.2 Protect the `dev` Branch

1. Click **Add branch protection rule** again
2. **Branch name pattern:** `dev`
3. Enable:
   - ‚úÖ **Require a pull request before merging** (forces PR from feature branches)
   - ‚ùå **Require approvals** - UNCHECK (allows you to merge your own PRs)
   - ‚úÖ **Require status checks to pass before merging**
     - ‚úÖ **Require branches to be up to date before merging**
     - **Add required status checks:**
       - `Test CLI Init`
       - `Shellcheck`
   - ‚ùå **Do not allow bypassing** - UNCHECK (gives you flexibility on dev)
4. Click **Create**

**Result:** Feature branches must:
- Create PR to `dev` (not directly to `main`)
- Pass CI checks before merging

## Step 6: Configure Notifications

Set up notifications for security alerts:

1. Click on your **profile icon** (top right) ‚Üí **Settings**
2. In the left sidebar, click **Notifications**
3. Scroll down to the **System** section
4. Enable the following:
   - ‚úÖ **Dependabot alerts: New vulnerabilities** - "When you're given access to Dependabot alerts automatically receive notifications when a new vulnerability is found in one of your dependencies."
   - ‚úÖ **Dependabot alerts: Email digest** - "Email a regular summary of Dependabot alerts for up to 10 of your repositories."
   - ‚úÖ **Security campaign emails** - "Receive email notifications about security campaigns in repositories where you have access to security alerts."

**Result:** You'll now receive email notifications whenever security issues are detected in your repositories.

## Step 7: Verify Everything Works

### 7.1 Test CI Pipeline

```bash
# Create a test branch
git checkout -b test/ci-pipeline

# Make a small change
echo "# Test" >> README.md

# Commit and push
git add README.md
git commit -m "test: verify CI pipeline"
git push origin test/ci-pipeline

# Create a PR on GitHub: test/ci-pipeline -> main
# Verify CI pipeline runs and passes
```

### 7.2 Test Dependabot

Dependabot runs weekly, but you can trigger it manually:

1. Go to **Insights** ‚Üí **Dependency graph** ‚Üí **Dependabot**
2. Click **Check for updates**

### 7.3 Test Secret Scanning

If enabled, try pushing a test secret:

```bash
# This should be blocked by local pre-commit hook
echo "API_KEY=test123" > secret.txt
git add secret.txt
git commit -m "test: secret scanning"
# Blocked locally!

# If you bypass local hook with --no-verify, GitHub will block the push
```

## Workflow Files Reference

### `.github/workflows/ci.yml`

**Purpose:** Continuous Integration pipeline

**Triggers:**
- Push to `main` branch
- Pull requests to `main` branch

**Jobs:**
1. **Shellcheck** - Lints shell scripts
2. **Test CLI Init** - Verifies the Forge CLI works

### `.github/dependabot.yml`

**Purpose:** Automated dependency updates

**Configuration:**
- **GitHub Actions ecosystem:** Scans workflow files
  - Schedule: Weekly
  - Groups updates

## Troubleshooting

### Workflows Not Appearing in Actions Tab

**Symptoms:** Actions tab shows "Get started with GitHub Actions" instead of workflows

**Causes:**
1. Workflow files not committed/pushed
2. Workflow files in wrong directory
3. YAML syntax errors
4. GitHub Actions disabled in repo settings

**Solutions:**
```bash
# 1. Verify files are committed
git ls-files .github/workflows/

# 2. Verify files are pushed
git log --oneline --name-only | grep workflows

# 3. Validate YAML syntax
npx js-yaml .github/workflows/ci.yml

# 4. Check repo settings
# Go to Settings ‚Üí Actions ‚Üí General ‚Üí Verify "Allow all actions" is selected
```

## Security Best Practices

1. **Enable all security features:**
   - ‚úÖ Dependabot alerts
   - ‚úÖ Secret scanning
   - ‚úÖ Push protection

2. **Protect main branch:**
   - Require PR reviews
   - Require status checks to pass
   - Prevent force pushes

3. **Use local pre-commit hooks:**
   - Catch secrets before pushing
   - Enforce code quality locally
   - Faster feedback loop

## Related Documentation

- [CI/CD Pipeline Documentation](./overview.md)
- [Git Workflow Guide](./git_workflow.md)
- [How to Commit Guide](./how_to_commit.md)
- [ADR-039: CI/CD Pipeline Strategy](../../docs/adr/039_ci_cd_pipeline.md)
- [ADR-040: Security Scanning Strategy](../../docs/adr/040_security_scanning_strategy.md)
- [Manual Setup Guide](../../TASKS/active/0067_MANUAL_SETUP_GUIDE.md)

## External Resources

- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Dependabot Documentation](https://docs.github.com/en/code-security/dependabot)
- [Secret Scanning Documentation](https://docs.github.com/en/code-security/secret-scanning)

```

## File: guides/cicd/how_to_commit.md
```md
# How to Commit Changes - Step-by-Step Guide

This guide walks you through committing changes to the quantum-diamond-forge project, including pre-commit hook validation and conventional commit format.

## Prerequisites

- Git configured with hooks path: `git config core.hooksPath .githooks`
- Pre-commit hook is executable: `chmod +x .githooks/pre-commit`

## Standard Commit Workflow

### Step 1: Check Current Status

```bash
# See what files have changed
git status

# See detailed changes
git diff
```

### Step 2: Stage Files

**Option A: Stage specific files (recommended)**
```bash
git add path/to/file1.js
git add path/to/file2.md
git add path/to/file3.yml
```

**Option B: Stage all changes**
```bash
git add .
# or
git add --all
```

**Option C: Interactive staging (stage specific lines)**
```bash
git add -p
# Git will show each change and ask: Stage this hunk [y,n,q,a,d,e,?]?
# y = yes, n = no, q = quit, a = all, d = don't stage, e = edit
```

### Step 3: Review Staged Changes

**Quick summary (recommended):**
```bash
# See list of staged files
git status

# Even shorter
git status -s
```

**Detailed diff (optional):**
```bash
# See detailed changes (can be verbose)
git diff --cached

# Press 'q' to exit the diff view
```

**‚ö†Ô∏è IMPORTANT:** Always review your staged changes before committing!

### Step 4: Commit with Conventional Format

```bash
git commit -m "<type>(<scope>): <subject>

<body>

<footer>"
```

**Commit Types:**
- `feat:` - New feature
- `fix:` - Bug fix
- `docs:` - Documentation changes
- `style:` - Code formatting (no logic change)
- `refactor:` - Code restructuring
- `test:` - Adding/updating tests
- `chore:` - Maintenance tasks (dependencies, build)
- `ci:` - CI/CD changes
- `perf:` - Performance improvements

**Example:**
```bash
git commit -m "feat(security): configure GitHub Advanced Security

- Add Dependabot for dependency scanning
- Add CodeQL workflow for security analysis
- Update CI/CD documentation with security guide

Refs: TASK-0067, ADR-040"
```

### Step 5: Pre-commit Hook Validation

**What happens automatically:**
1. ‚úÖ Hook runs: `.githooks/pre-commit`
2. ‚úÖ Validates no `.env` files (except `.env.example`)
3. ‚úÖ Scans for hardcoded secrets (API keys, tokens, passwords)
4. ‚úÖ If validation passes ‚Üí commit succeeds
5. ‚ùå If violations found ‚Üí commit blocked

**If commit is blocked:**
```bash
# Example error:
COMMIT BLOCKED: Violations found.
VIOLATION: packages/backend/config.js:12 -> OPENAI_API_KEY=<REDACTED>
Fix by removing secrets or using '<REDACTED>'.

# Fix the issue:
# 1. Remove the hardcoded secret
# 2. Use environment variable instead: process.env.OPENAI_API_KEY
# 3. Try committing again
```

**Bypass hook (ONLY if absolutely necessary):**
```bash
git commit --no-verify -m "your message"
# ‚ö†Ô∏è WARNING: Only use --no-verify if you're certain there are no secrets!
```

### Step 6: Push to Remote

```bash
# Push to current branch
git push

# Push to specific branch
git push origin feature/branch-name

# Push to main
git push origin main
```

## Example: Committing TASK-0067 Security Configuration

```bash
# 1. Check status
git status

# 2. Stage security configuration files
git add .github/dependabot.yml
git add .github/workflows/codeql.yml
git add docs/ci-cd/README.md
git add docs/ci-cd/GIT_WORKFLOW.md
git add docs/ci-cd/HOW_TO_COMMIT.md
git add adrs/040_security_scanning_strategy.md
git add adrs/041_git_workflow_automation.md
git add TASKS/in-progress/008_configure_github_security.md
git add TASKS/backlog/009_enhance_precommit_hooks.md
git add scripts/capture_snapshot.js

# Note: Deleted file (.githooks/pre-commit.sh) will be automatically staged
# when you run 'git add .' or will show in 'git status' as deleted

# 3. Review staged changes (quick summary)
git status

# Or see detailed diff (verbose, press 'q' to exit)
# git diff --cached

# 4. Commit with conventional format
git commit -m "feat(security): configure GitHub Advanced Security

- Add Dependabot for npm and GitHub Actions dependency scanning
- Add CodeQL workflow for JavaScript/TypeScript security analysis
- Update CI/CD documentation with comprehensive security scanning guide
- Create ADR-041 for git workflow automation strategy
- Create git workflow quick reference guide
- Enhance snapshot script to exclude agents/feedback directory
- Remove deprecated pre-commit.sh shell script

Deliverables:
- .github/dependabot.yml (weekly scans, grouped PRs)
- .github/workflows/codeql.yml (security-extended queries)
- docs/ci-cd/README.md (175-line security guide, pre-commit hook docs)
- docs/ci-cd/GIT_WORKFLOW.md (conventional commits, aliases, best practices)
- adrs/041_git_workflow_automation.md (no automated git scripts)
- TASKS/backlog/009_enhance_precommit_hooks.md (future ESLint/Prettier integration)

Refs: TASK-0067, ADR-040, ADR-041"

# 5. Pre-commit hook runs automatically (validates no secrets)

# 6. Push to GitHub
git push origin main
```

## Testing Pre-commit Hook

### Test 1: Verify Hook Blocks Secrets

```bash
# Create a test file with a hardcoded secret
echo "OPENAI_API_KEY=<REDACTED>" > test-secret.txt

# Try to commit (should be BLOCKED)
git add test-secret.txt
git commit -m "test: verify pre-commit hook blocks secrets"

# Expected output:
# COMMIT BLOCKED: Violations found.
# VIOLATION: test-secret.txt:1 -> OPENAI_API_KEY=<REDACTED>
# Fix by removing secrets or using '<REDACTED>'.

# Clean up
git reset HEAD test-secret.txt
rm test-secret.txt
```

### Test 2: Verify Hook Blocks .env Files

```bash
# Create a .env file
echo "DATABASE_URL=postgres://localhost" > .env

# Try to commit (should be BLOCKED)
git add .env
git commit -m "test: verify pre-commit hook blocks .env files"

# Expected output:
# COMMIT BLOCKED: Violations found.
# BLOCKED .env file: .env
# Fix by removing secrets or using '<REDACTED>'.

# Clean up
git reset HEAD .env
rm .env
```

### Test 3: Verify Hook Allows Safe Code

```bash
# Create a safe file with environment variable reference
echo "const apiKey = process.env.OPENAI_API_KEY;" > test-safe.js

# Commit (should SUCCEED)
git add test-safe.js
git commit -m "test: verify pre-commit hook allows safe code"

# Expected: Commit succeeds (no violations)

# Clean up
git reset HEAD~1  # Undo last commit
rm test-safe.js
```

## Common Issues and Solutions

### Issue 1: Pre-commit Hook Not Running

**Symptoms:** Commits succeed without validation

**Solution:**
```bash
# Verify hooks path is configured
git config core.hooksPath
# Should output: .githooks

# If not set, configure it
git config core.hooksPath .githooks

# Make hook executable
chmod +x .githooks/pre-commit

# Verify hook exists
ls -la .githooks/pre-commit
```

### Issue 2: Hook Blocks Legitimate Code

**Symptoms:** Hook blocks code that uses environment variables

**Example:**
```javascript
// This might be flagged if not properly formatted
const key = API_KEY;  // ‚ùå Flagged (looks like hardcoded value)

// Use these patterns instead:
const key = process.env.API_KEY;  // ‚úÖ Safe
const key = import.meta.env.VITE_API_KEY;  // ‚úÖ Safe
const key = config.apiKey;  // ‚úÖ Safe
```

**Solution:** Use whitelisted patterns (see `.githooks/pre-commit` for full list)

### Issue 3: Accidentally Committed Secret

**‚ö†Ô∏è CRITICAL - Act Immediately:**

```bash
# 1. IMMEDIATELY revoke the secret in the service provider
# (e.g., regenerate API key in OpenAI dashboard)

# 2. Remove from git history (if not yet pushed)
git reset HEAD~1  # Undo last commit
# Fix the file, then commit again

# 3. If already pushed, use git filter-branch
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch path/to/file" \
  --prune-empty --tag-name-filter cat -- --all

# 4. Force push (‚ö†Ô∏è coordinate with team!)
git push origin --force --all

# 5. Update environment variables with new secret
```

## Git Aliases (Optional Shortcuts)

Add these to `~/.gitconfig` for faster workflows:

```gitconfig
[alias]
    # Quick status
    st = status -sb

    # Stage all changes
    aa = add --all

    # Commit with message
    cm = commit -m

    # Show staged changes
    staged = diff --cached

    # Amend last commit
    amend = commit --amend --no-edit

    # Pretty log
    lg = log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit
```

**Usage:**
```bash
git st              # Instead of: git status -sb
git aa              # Instead of: git add --all
git staged          # Instead of: git diff --cached
git cm "fix: typo"  # Instead of: git commit -m "fix: typo"
```

## Best Practices

1. **Commit often** - Small, focused commits are easier to review and revert
2. **Write clear messages** - Use conventional commit format
3. **Review before committing** - Always run `git diff --cached`
4. **Test locally** - Run `npm run lint` and `npm run test:unit` before committing
5. **Never bypass hooks** - Only use `--no-verify` in emergencies
6. **Keep commits atomic** - One logical change per commit
7. **Reference tasks/issues** - Include `Refs: TASK-XXX` in commit body

## After Pushing to GitHub

Once you push, the following automated checks will run:

1. **CI Pipeline** (`.github/workflows/ci.yml`)
   - Linting
   - Unit tests
   - Frontend build

2. **CodeQL Analysis** (`.github/workflows/codeql.yml`)
   - Security vulnerability scanning
   - Results in Security tab

3. **Dependabot** (`.github/dependabot.yml`)
   - Dependency vulnerability scanning
   - Automatic PRs for updates

4. **Secret Scanning** (if enabled)
   - Detects committed secrets
   - Alerts in Security tab

Check the **Actions** tab and **Security** tab on GitHub to verify all checks pass.

## References

- [Git Workflow Quick Reference](./git_workflow.md)
- [CI/CD Pipeline Documentation](./overview.md)
- [ADR-041: Git Workflow Automation](../../docs/adr/041_git_workflow_automation.md)
- [Conventional Commits Specification](https://www.conventionalcommits.org/)

```

## File: guides/cicd/overview.md
```md
# CI/CD Pipeline & Development Workflow

## Overview

This document outlines the Continuous Integration (CI) pipeline and the standard development workflow for projects built with the **Quantum Diamond Forge** protocol. It details the lifecycle of a code change from a developer's workstation to the main branch on GitHub.

## Table of Contents

1. [Workflow Diagram](#workflow-diagram)
2. [Development Workflow Phases](#development-workflow-phases)
3. [Security Scanning Results Guide](#security-scanning-results-guide)
4. [How to Commit Changes](./how_to_commit.md) - Step-by-step commit guide with pre-commit hook testing
5. [Git Workflow Quick Reference](./git_workflow.md) - Conventional commits, aliases, and best practices
6. [Related Documentation](#related-documentation)

## Related Documentation

- **[GitHub Repository Setup Guide](./github_setup.md)** - Configure GitHub Actions, security scanning, and branch protection
- **[How to Commit Changes](./how_to_commit.md)** - Step-by-step commit guide with pre-commit hook testing
- **[Git Workflow Guide](./git_workflow.md)** - Detailed guide on git commands, conventional commits, and pre-commit hooks
- **[ADR-039: CI/CD Pipeline Strategy](../../docs/adr/039_ci_cd_pipeline.md)** - Architectural decision for CI/CD approach
- **[ADR-040: Security Scanning Strategy](../../docs/adr/040_security_scanning_strategy.md)** - Security scanning tools and philosophy
- **[ADR-041: Git Workflow Automation](../../docs/adr/041_git_workflow_automation.md)** - Git workflow best practices

## Branching Strategy

This protocol supports **flexible branching strategies** based on team size:

### Solo Developer (Simplified)
```
feature/* ‚Üí main (via Pull Request)
```

### Team / Staged Releases (Recommended)
```
feature/* ‚Üí dev ‚Üí main
```

### Enterprise / Multi-Environment
```
feature/* ‚Üí dev ‚Üí test ‚Üí main
```

### Branch Purposes

| Branch | Purpose | CI Runs | Deployment |
|--------|---------|---------|------------|
| `feature/*` | Active development | ‚úÖ On PR | None |
| `dev` | Integration testing, batch features | ‚úÖ On push/PR | Dev environment (optional) |
| `test` | QA/staging (optional) | ‚úÖ On push/PR | Test environment (optional) |
| `main` | Production-ready | ‚úÖ On push/PR | Production |

### Workflow (Team / Staged Releases)

1. **Feature Development:**
   ```bash
   git checkout -b feature/add-new-feature
   # Make changes, commit, push
   git push origin feature/add-new-feature
   # Create PR: feature/add-new-feature ‚Üí dev
   ```

2. **Integration Testing (dev):**
   - Merge feature PRs into `dev`
   - CI pipeline runs automatically
   - Test integration with other features
   - Batch multiple features for the next release

3. **Production Release (main):**
   ```bash
   # Create PR: dev ‚Üí main
   # After approval and CI passes, merge
   # Tag release: git tag v1.0.0 && git push --tags
   ```

### Branch Protection

Recommended protection for `dev` and `main`:
- ‚úÖ CI pipeline checks (linting, tests, build)
- ‚úÖ CodeQL security analysis (if enabled)
- ‚úÖ PR review required (for `main`, optional for `dev`)
- ‚úÖ Status checks must pass before merge

See [GitHub Repository Setup Guide](./github_setup.md) for configuration details.

## Workflow Diagram

The following sequence diagram illustrates the interaction between the Developer, their Local Workstation, and the specific entities within GitHub (Branches, PRs, CI).

```mermaid
---
config:
  theme: base
---
sequenceDiagram
    autonumber
    participant Dev as Developer
    participant Local as Local Workstation
    participant FeatBranch as Remote Feature Branch
    participant PR as Pull Request
    participant CI as GitHub Actions (CI)
    participant MainBranch as Remote Main Branch

    Note over Dev, Local: 1. Feature Start
    Dev->>Local: git checkout -b feature/new-feature

    Note over Dev, Local: 2. Development Loop
    loop Coding & Local Testing
        Dev->>Local: Write Code
        Dev->>Local: npm run lint (Check Style)
        Dev->>Local: npm run test:unit (Verify Logic)
        Dev->>Local: (Optional) Manual Security Scan
    end

    Note over Dev, Local: 3. Commit & Push (Defense in Depth)
    Dev->>Local: git add .
    Local->>Local: Pre-commit Hook (Secret Detection)
    Note right of Local: üõë Blocking Gate:<br/>- No .env files<br/>- No hardcoded secrets<br/>- Blocks commit if violations found

    Dev->>Local: git commit -m "feat: add new feature"

    rect rgb(255, 255, 240)
        Note right of Local: ‚ö†Ô∏è Post-Commit Hook (Informational):<br/>- Auto-runs 'npm audit' (High Severity)<br/>- Checks local Dependabot status<br/>- Warns Dev immediately (does not block)
        Local-->>Dev: Display "Security Health Report"
    end

    Dev->>Local: git push -u origin feature/new-feature
    Local->>FeatBranch: Create/Update Branch

    Note over Dev, PR: 4. Pull Request
    Dev->>PR: Create PR (Feature -> Main)

    Note over PR, CI: 5. Automated Checks
    PR->>CI: Trigger "CI Pipeline" Workflow

    par CI Pipeline
        rect rgb(240, 248, 255)
            Note right of CI: CI Execution
            CI->>CI: Checkout Code
            CI->>CI: Install Dependencies
            CI->>CI: Linting & Tests
            CI->>CI: Build Frontend
        end
        CI-->>PR: Report Status (‚úÖ/‚ùå)
    and Security Checks
        rect rgb(255, 240, 245)
            Note right of PR: GitHub Security
            PR->>PR: Dependabot Scan
            PR->>PR: CodeQL Analysis
            PR->>PR: Secret Scanning
        end
        PR-->>Dev: Report Vulnerabilities (in PR Interface)
    end

    alt Checks Fail
        PR-->>Dev: Notify Failure
        Dev->>Local: Fix Code & Push Again
        Local->>FeatBranch: Update Branch
        FeatBranch->>PR: Update PR
        PR->>CI: Re-trigger CI
    else Checks Pass
        Note over Dev, MainBranch: 6. Review & Merge
        Dev->>PR: Request Review
        PR->>MainBranch: Merge PR to 'main'

        Note over MainBranch, FeatBranch: 7. Cleanup
        MainBranch->>FeatBranch: Delete Remote Branch
    end

    Note over Dev, Local: 8. Local Cleanup
    Dev->>Local: git checkout main
    Dev->>Local: git pull origin main
    Local->>MainBranch: Fetch Latest
    Dev->>Local: git branch -d feature/new-feature
```

## Detailed Workflow Steps

### Phase 1: Developer Workstation (Local)

1.  **Create Feature Branch**
    *   **Command:** `git checkout -b feature/<name>`
    *   **Purpose:** Isolate changes from the stable `main` codebase.

2.  **Development & Verification**
    *   **Process:** Write code, update tests.
    *   **Verification:**
    *   Run `npm run lint` and `npm run test:unit`.
    *   **Post-Commit Hook:** After commit, an informational `npm audit --audit-level=high --production` runs and displays a Security Health Report (does not block).

3.  **Commit & Push**
    *   **Command:** `git commit` and `git push`.
    *   **Pre-commit Hook:** Automatically runs `.githooks/pre-commit` to validate:
        *   No `.env` files committed (except `.env.example`)
        *   No hardcoded secrets (API keys, tokens, passwords)
        *   Blocks commit if violations found
    *   **Entity:** Updates the **Remote Feature Branch** (`origin/feature/<name>`).
    *   **Best Practice:** Use [conventional commits](./GIT_WORKFLOW.md#conventional-commit-format) (e.g., `feat:`, `fix:`, `docs:`)

### Phase 2: GitHub (Remote)

4.  **Create Pull Request (PR)**
    *   **Action:** Create a PR merging **Remote Feature Branch** into **Remote Main Branch**.
    *   **Purpose:** This is the central hub for review and automated checks.

5.  **Automated Checks**
    *   **CI Pipeline:** GitHub Actions runs linting, testing, and building. Reports success/failure back to the PR.
    *   **Security Scans:**
        *   **Dependabot:** Scans dependencies for vulnerabilities. If found, it alerts in the PR or creates a new PR.
        *   **Secret Scanning:** Checks for committed secrets (API keys, tokens).
        *   **CodeQL:** (If enabled) Performs static analysis for security flaws.
    *   **Reporting:** All results are displayed in the "Checks" section of the PR interface.


6.  **Code Review & Merge**
    *   **Action:** If all checks pass (Green ‚úÖ), the PR is merged.
    *   **Result:** Code moves from **Remote Feature Branch** to **Remote Main Branch**.

7.  **Remote Cleanup**
    *   **Action:** The **Remote Feature Branch** is deleted to keep the repository clean.

### Phase 3: Developer Workstation (Local Cleanup)

8.  **Sync & Cleanup**
    *   **Action:** Pull the latest `main` from **Remote Main Branch** and delete the local feature branch.

---

## Security Scanning Results Guide

This section explains how to interpret and respond to security scanning results from our automated tools.

### Dependabot Alerts

**What it does:** Scans `package.json` and `package-lock.json` for known vulnerabilities in dependencies.

**Where to find results:**
- **Security tab** ‚Üí Dependabot alerts
- **Pull Requests** ‚Üí Dependabot automatically opens PRs for updates

**How to interpret:**
- **Critical/High:** Address immediately (within 48 hours)
- **Medium:** Address within 1 week
- **Low:** Address during regular maintenance

**Response actions:**
1. Review the Dependabot PR description for vulnerability details
2. Check if the update includes breaking changes (review CHANGELOG)
3. Verify tests pass in the Dependabot PR
4. Merge the PR or manually update the dependency
5. If update causes issues, document in PR and investigate alternatives

**Example Dependabot PR:**
```
Title: Bump axios from 0.21.1 to 1.6.0
Labels: dependencies, security

Description:
- Fixes CVE-2023-45857 (High severity)
- Changelog: https://github.com/axios/axios/releases
```

### CodeQL Analysis

**What it does:** Static code analysis to detect security vulnerabilities (SQL injection, XSS, path traversal, etc.)

**Where to find results:**
- **Security tab** ‚Üí Code scanning alerts
- **Pull Request checks** ‚Üí CodeQL analysis status

**How to interpret:**
- **Error:** Security vulnerability detected, must fix before merge
- **Warning:** Potential issue, review and address if applicable
- **Note:** Informational, no action required

**Common alerts:**
- **Unvalidated user input:** Always validate/sanitize user input
- **SQL injection:** Use parameterized queries (we use Supabase client, which handles this)
- **XSS vulnerabilities:** Sanitize output, use React's built-in XSS protection
- **Path traversal:** Validate file paths before file operations
- **Hardcoded credentials:** Never commit secrets (use environment variables)

**Response actions:**
1. Click on the alert in the Security tab to see details
2. Review the code path highlighted by CodeQL
3. Determine if it's a true positive or false positive
4. If true positive: Fix the vulnerability and push a new commit
5. If false positive: Document why it's safe and dismiss the alert with justification

**Example CodeQL alert:**
```
Alert: Unvalidated user input in file path
Severity: High
File: packages/backend/api/controllers/fileController.js:45
Recommendation: Validate and sanitize the file path before use
```

### Secret Scanning

**What it does:** Detects accidentally committed secrets (API keys, tokens, passwords)

**Where to find results:**
- **Security tab** ‚Üí Secret scanning alerts
- **Push protection:** Blocks commits containing secrets (if enabled)

**How to interpret:**
- **Active:** Secret is currently in the repository
- **Resolved:** Secret has been removed or revoked

**Response actions (CRITICAL - Act immediately):**
1. **Revoke the exposed secret** in the service provider (e.g., regenerate API key)
2. **Remove the secret from git history** (use `git filter-branch` or BFG Repo-Cleaner)
3. **Update environment variables** with the new secret
4. **Verify the secret is not in any commits** (check git log)
5. **Document the incident** and review how it happened

**Prevention:**
- Use `.env` files (already in `.gitignore`)
- Store secrets in user profile (`~/.zshrc` or `~/.bashrc`)
- Use `npm audit` locally before committing
- Enable push protection in GitHub settings

**Example secret scanning alert:**
```
Alert: GitHub Personal Access Token detected
File: packages/backend/.env
Commit: abc123def456
Status: Active
Action Required: Revoke token immediately
```

### Local Security Checks

**Before every commit, run:**
```bash
# Check for vulnerable dependencies
npm audit

# Fix automatically fixable vulnerabilities
npm audit fix

# Review high-severity vulnerabilities
npm audit --audit-level=high
```

**Interpreting `npm audit` output:**
```
found 3 vulnerabilities (1 moderate, 2 high)

Moderate: Prototype Pollution in lodash
  Package: lodash
  Patched in: >=4.17.21
  Fix available: npm audit fix

High: Regular Expression Denial of Service in semver
  Package: semver
  Patched in: >=7.5.2
  Fix available: npm audit fix
```

**Response:**
- Run `npm audit fix` to auto-fix
- If auto-fix not available, manually update the package
- If no fix available, assess risk and consider alternatives

### Security Check Status in PRs

All PRs must pass these checks before merge:

| Check | Status | Action if Failed |
|-------|--------|------------------|
| **CI Pipeline** | ‚úÖ Must pass | Fix linting/test errors |
| **CodeQL** | ‚úÖ Must pass | Fix security vulnerabilities |
| **Dependabot** | ‚ö†Ô∏è Advisory | Review and merge dependency updates |
| **Secret Scanning** | üö® Must pass | Revoke and remove secrets immediately |

**Green ‚úÖ = Safe to merge**
**Yellow ‚ö†Ô∏è = Review required**
**Red üö® = Blocking issue, must fix**

### Escalation Path

If you encounter a security issue you're unsure how to handle:

1. **Do not merge the PR**
2. **Tag the issue** with `security` label
3. **Document the issue** in the PR comments
4. **Consult ADR-040** for security scanning strategy
5. **Reach out** to the team lead or security contact

### Additional Resources

- [GitHub Security Best Practices](https://docs.github.com/en/code-security)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [npm audit documentation](https://docs.npmjs.com/cli/v8/commands/npm-audit)
- ADR-040: Security Scanning Strategy

```

## File: guides/cicd/security_scanning.md
```md
# Security Vulnerability Scanning Guide

## Overview

This guide covers how to scan for security vulnerabilities in your dependencies using GitHub CLI and integrate security scanning into your shift-left development process.

## Table of Contents

- [Prerequisites](#prerequisites)
- [Scanning with GitHub CLI](#scanning-with-github-cli)
- [Understanding Dependabot Alerts](#understanding-dependabot-alerts)
- [Shift-Left Security Integration](#shift-left-security-integration)
- [Local Security Scanning](#local-security-scanning)
- [Automated Workflows](#automated-workflows)
- [Best Practices](#best-practices)

## Prerequisites

### Install GitHub CLI

```bash
# macOS
brew install gh

# Authenticate with GitHub
gh auth login
```

### Required Permissions

Ensure your GitHub token has the following scopes:
- `repo` - Full control of private repositories
- `read:org` - Read org and team membership
- `workflow` - Update GitHub Action workflows

## Scanning with GitHub CLI

### Check Authentication Status

```bash
gh auth status
```

### View All Dependabot Alerts

```bash
# List all alerts
gh api repos/OWNER/REPO/dependabot/alerts

# Pretty formatted output
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq '.[] | {
    number: .number,
    severity: .security_advisory.severity,
    package: .dependency.package.name,
    summary: .security_advisory.summary,
    patched_version: .security_advisory.vulnerabilities[0].first_patched_version.identifier
  }'
```

### Filter by Severity

```bash
# High severity only
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq '.[] | select(.security_advisory.severity == "high") | {
    package: .dependency.package.name,
    summary: .security_advisory.summary
  }'

# Critical and High severity
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq '.[] | select(.security_advisory.severity == "critical" or .security_advisory.severity == "high")'
```

### Count Open Alerts

```bash
# Total open alerts
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq '[.[] | select(.state == "open")] | length'

# By severity
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq 'group_by(.security_advisory.severity) | map({severity: .[0].security_advisory.severity, count: length})'
```

### Get Detailed Alert Information

```bash
# Get specific alert details
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts/ALERT_NUMBER

# Get fix recommendations
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq '.[] | {
    package: .dependency.package.name,
    current_version: .dependency.package.version,
    patched_version: .security_advisory.vulnerabilities[0].first_patched_version.identifier,
    cvss_score: .security_advisory.cvss.score
  }'
```

## Understanding Dependabot Alerts

### Alert Severity Levels

- **Critical**: Immediate action required (CVSS 9.0-10.0)
- **High**: Should be addressed quickly (CVSS 7.0-8.9)
- **Medium**: Address in normal development cycle (CVSS 4.0-6.9)
- **Low**: Address when convenient (CVSS 0.1-3.9)

### Alert States

- **open**: Vulnerability is present and unresolved
- **dismissed**: Manually dismissed by a user
- **fixed**: Dependency has been updated to a non-vulnerable version

## Shift-Left Security Integration

### Why Shift-Left Security?

Shift-left security means integrating security checks **earlier** in the development process:

‚úÖ **Benefits:**
- Catch vulnerabilities before they reach production
- Reduce cost of fixes (cheaper to fix in development)
- Faster feedback loop for developers
- Prevent vulnerable code from being committed

‚ùå **Without Shift-Left:**
- Vulnerabilities discovered in production
- Emergency patches and hotfixes
- Potential security incidents
- Higher remediation costs

### Pre-Commit Security Checks

Yes, you **should** integrate security scanning into your pre-commit process! Here's how:

## Local Security Scanning

### 1. NPM Audit (Built-in)

```bash
# Run npm audit
npm audit

# Get JSON output
npm audit --json

# Fix automatically (use with caution)
npm audit fix

# Fix only production dependencies
npm audit fix --production-only

# Dry run to see what would be fixed
npm audit fix --dry-run
```

### 2. Create a Pre-Commit Security Check

Add to your `package.json`:

```json
{
  "scripts": {
    "security:check": "npm audit --audit-level=high",
    "security:fix": "npm audit fix",
    "precommit:security": "npm audit --audit-level=critical --production"
  }
}
```

### 3. Integrate with Husky/lint-staged

Update your `.husky/pre-commit` or create one:

```bash
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run security audit before commit
echo "üîí Running security audit..."
npm audit --audit-level=high --production

if [ $? -ne 0 ]; then
  echo "‚ùå Security vulnerabilities found! Please fix before committing."
  echo "Run 'npm audit' for details or 'npm audit fix' to attempt automatic fixes."
  exit 1
fi

# Continue with other pre-commit checks
npx lint-staged
```

### 4. Alternative: Use Snyk CLI

Snyk provides more comprehensive scanning:

```bash
# Install Snyk
npm install -g snyk

# Authenticate
snyk auth

# Test for vulnerabilities
snyk test

# Monitor project (sends results to Snyk dashboard)
snyk monitor

# Test and fail on high severity
snyk test --severity-threshold=high
```

### 5. GitHub CLI Pre-Push Check

Create a script to check before pushing:

```bash
#!/bin/bash
# .git/hooks/pre-push or scripts/pre-push-security.sh

echo "üîç Checking for Dependabot alerts..."

OPEN_ALERTS=$(gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts \
  --jq '[.[] | select(.state == "open" and (.security_advisory.severity == "critical" or .security_advisory.severity == "high"))] | length')

if [ "$OPEN_ALERTS" -gt 0 ]; then
  echo "‚ö†Ô∏è  Warning: $OPEN_ALERTS critical/high severity alerts found in GitHub!"
  echo "Run: gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts --jq '.[] | select(.state == \"open\")' for details"

  read -p "Continue with push? (y/n) " -n 1 -r
  echo
  if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    exit 1
  fi
fi
```

## Automated Workflows

### Recommended Shift-Left Security Strategy

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Development Workflow                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  1. Local Development                                        ‚îÇ
‚îÇ     ‚îî‚îÄ> npm audit (manual check)                            ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  2. Pre-Commit Hook                                          ‚îÇ
‚îÇ     ‚îî‚îÄ> npm audit --audit-level=high                        ‚îÇ
‚îÇ     ‚îî‚îÄ> Fail on critical/high vulnerabilities               ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  3. Pre-Push Hook (Optional)                                 ‚îÇ
‚îÇ     ‚îî‚îÄ> Check GitHub Dependabot alerts via CLI              ‚îÇ
‚îÇ     ‚îî‚îÄ> Warn on open critical/high alerts                   ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  4. CI/CD Pipeline                                           ‚îÇ
‚îÇ     ‚îî‚îÄ> npm audit in GitHub Actions                         ‚îÇ
‚îÇ     ‚îî‚îÄ> Dependabot auto-updates                             ‚îÇ
‚îÇ     ‚îî‚îÄ> SAST/DAST scanning                                  ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  5. Production Monitoring                                    ‚îÇ
‚îÇ     ‚îî‚îÄ> Continuous Dependabot monitoring                    ‚îÇ
‚îÇ     ‚îî‚îÄ> Security alerts via GitHub                          ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Add to package.json Scripts

```json
{
  "scripts": {
    "security:audit": "npm audit",
    "security:audit:ci": "npm audit --audit-level=moderate --production",
    "security:fix": "npm audit fix",
    "security:check:github": "gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts --jq '.[] | select(.state == \"open\")'",
    "precommit": "npm run security:audit && lint-staged"
  }
}
```

### GitHub Actions Workflow

Create `.github/workflows/security-scan.yml`:

```yaml
name: Security Scan

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  security-audit:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run npm audit
        run: npm audit --audit-level=moderate
        continue-on-error: true

      - name: Check Dependabot alerts
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh api repos/${{ github.repository }}/dependabot/alerts \
            --jq '.[] | select(.state == "open") | {severity: .security_advisory.severity, package: .dependency.package.name}'
```

## Best Practices

### 1. **Regular Scanning**
- Run `npm audit` before every commit
- Check Dependabot alerts weekly
- Review security advisories for your dependencies

### 2. **Prioritize Fixes**
- **Critical/High**: Fix immediately
- **Medium**: Fix within sprint
- **Low**: Fix during maintenance windows

### 3. **Keep Dependencies Updated**
```bash
# Check for outdated packages
npm outdated

# Update to latest within semver range
npm update

# Update to latest (breaking changes possible)
npm install package@latest
```

### 4. **Use Dependabot Auto-Updates**

Enable in `.github/dependabot.yml`:

```yaml
version: 2
updates:
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 10
    reviewers:
      - "your-team"
    labels:
      - "dependencies"
      - "security"
```

### 5. **Monitor Production**
- Enable GitHub security alerts
- Set up Slack/email notifications for new vulnerabilities
- Use GitHub Security Advisory Database

### 6. **Document Exceptions**
If you must dismiss an alert:
```bash
# Dismiss with reason
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts/ALERT_NUMBER \
  -X PATCH \
  -f state=dismissed \
  -f dismissed_reason=no_bandwidth \
  -f dismissed_comment="Will address in Q2 security sprint"
```

## Quick Reference Commands

```bash
# Check auth
gh auth status

# List all open alerts
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts --jq '.[] | select(.state == "open")'

# Count by severity
gh api repos/richfrem/quantum-diamond-forge/dependabot/alerts --jq 'group_by(.security_advisory.severity) | map({severity: .[0].security_advisory.severity, count: length})'

# Local audit
npm audit

# Fix vulnerabilities
npm audit fix

# Production-only audit
npm audit --production

# Fail on high severity
npm audit --audit-level=high
```

## Recommended Pre-Commit Setup

**Balanced Approach** (Recommended for this project):

```bash
# Add to package.json
"scripts": {
  "precommit:security": "npm audit --audit-level=high --production"
}
```

**Why this approach?**
- ‚úÖ Catches critical and high severity issues
- ‚úÖ Only checks production dependencies (dev deps less critical)
- ‚úÖ Fast enough for pre-commit hook
- ‚úÖ Prevents vulnerable code from being committed
- ‚ùå Won't block on medium/low severity issues

## Conclusion

**Should you scan before pushing?**

**Yes!** Implement a **layered security approach**:

1. **Pre-commit**: Fast `npm audit` for critical/high severity
2. **Pre-push**: Optional GitHub Dependabot check (can be slow)
3. **CI/CD**: Comprehensive scanning in GitHub Actions
4. **Continuous**: Dependabot monitoring and auto-PRs

This shift-left approach catches vulnerabilities early, reduces security debt, and maintains a secure codebase without significantly slowing down development.

---

**Last Updated**: 2025-11-21
**Maintained By**: Development Team

```

## File: prompts/00_MASTER_PROTOCOL.md
```md
# Quantum Diamond Forge: Master Protocol (v2.0)

**Objective:**
Generate "Enterprise Benchmark" quality software specifications and code by orchestrating a "Human-in-the-Loop" workflow with high-end LLMs (Gemini 1.5 Pro, Claude 3.5 Sonnet, or Grok).

**The Concept:**
Instead of relying on a swarm of autonomous agents, **YOU + ANTIGRAVITY** are the orchestrator.
*   **You (The User):** Provide the vision and strategic decisions.
*   **Web LLM (Gemini/Claude):** The "Heavy Lifter" that generates rigorous specs from our prompts.
*   **Antigravity (IDE Agent):** The "Builder" that implements the code based on those specs.

This "Human-in-the-Loop" workflow ensures enterprise-grade quality without losing control.

---

## Phase 1: The Specification Loop

**Goal:** Create a "Gold Standard" documentation suite (`docs/`) that leaves no ambiguity for implementation.

### Step 1: Requirements Analysis
1.  Open `prompts/01_requirements_analysis.md`.
2.  Fill in your "Rough Idea" at the top.
3.  Paste the entire file into your Web LLM.
4.  **Review the Output:** Ensure it has a Feature Catalog (MoSCoW), Functional Requirements, and User Stories.
5.  **Save:** Create `docs/01_REQUIREMENTS.md` and paste the output there.

### Step 2: Architecture Design
1.  Open `prompts/02_architecture_design.md`.
2.  Paste it into the Web LLM (attach `docs/01_REQUIREMENTS.md` as context).
3.  **Review the Output:** Ensure it has C4 Diagrams (Mermaid), API Definitions, and Data Models.
4.  **Save:** Create `docs/02_ARCHITECTURE.md` and paste the output there.

### Step 3: Security & Compliance
1.  Open `prompts/03_security_compliance.md`.
2.  Paste it into the Web LLM (attach `docs/01_REQUIREMENTS.md` and `docs/02_ARCHITECTURE.md`).
3.  **Review the Output:** Ensure it has Threat Models (STRIDE) and AuthZ matrices.
4.  **Save:** Create `docs/03_SECURITY.md` and paste the output there.

### Step 4: Testing Strategy
1.  Open `prompts/04_testing_strategy.md`.
2.  Paste it into the Web LLM (attach previous docs).
3.  **Save:** Create `docs/04_TESTING.md`.

### Step 5: Implementation Plan
1.  Open `prompts/05_implementation_plan.md`.
2.  Paste it into the Web LLM (attach all 4 docs).
3.  **Save:** Create `docs/05_IMPLEMENTATION.md`.
4.  **Action:** This file will contain a `task.md` section. Copy that into your IDE's `task.md` to start coding!

---

## Phase 2: The Build Loop

**Goal:** Implement the spec using the Antigravity Agent (in your IDE).

1.  **Initialize:**
    *   Ensure `task.md` is populated from Step 5.
    *   Ensure `docs/` folder contains all 5 artifacts.

2.  **Execute:**
    *   Point your IDE Agent to the `task.md`.
    *   The Agent will read the `docs/` to understand *exactly* what to build.
    *   Iterate through the tasks until completion.

---

## Pro Tips
*   **Iterate:** If the LLM output isn't detailed enough, ask it to "Critique and Refine" before saving.
*   **Diagrams:** Use the Mermaid diagrams in `02_ARCHITECTURE.md` to visualize the system. You can render them in GitHub or your IDE.
*   **Context:** Always provide the previous documents as context for the next step. This ensures consistency.

```

## File: prompts/00_MASTER_PROTOCOL_LEAN.md
```md
# Quantum Diamond Forge - Master Protocol (Lean Mode)

**Version**: 2.1 Lean  
**Audience**: Solo developers, MVPs, prototypes, small teams  
**Philosophy**: Speed + Essential Rigor

---

## What is Lean Mode?

Lean Mode is a **streamlined variant** of Protocol v2.0 designed for:
- Solo developers building MVPs
- Prototypes and proof-of-concepts
- Small teams moving fast
- Projects that don't require full enterprise compliance

**What You Skip:**
- C4 Level 2-3 diagrams (keep Level 1 only)
- Detailed threat modeling tables (basic security checklist instead)
- Extensive non-functional requirements
- Full test pyramid (focus on unit + integration)

**What You Keep:**
- Core requirements (feature catalog, user stories)
- Basic architecture (C4 Level 1, API design, data models)
- Essential security (AuthN/AuthZ, encryption)
- Practical testing (unit + integration tests)
- Implementation plan

---

## The Lean Workflow

```mermaid
graph TD
    User["üë§ You"] -->|1. Idea| WebLLM["üß† Web LLM"]
    WebLLM -->|2. Lean Specs| Specs["üìÑ Essential Docs"]
    Specs -->|3. Guides| Agent["ü§ñ IDE Agent"]
    Agent -->|4. Builds| Code["üíª MVP Code"]
```

### Phase 1: Specification Loop (Lean)

#### Step 1: Requirements (Lean)
**Prompt**: `prompts/lean/01_requirements_analysis.md`

**Output**: `docs/01_REQUIREMENTS.md`
- Feature catalog (Must-Have + Should-Have only)
- 3-5 key user stories
- Basic acceptance criteria

**Time**: ~10 minutes

---

#### Step 2: Architecture (Lean)
**Prompt**: `prompts/lean/02_architecture_design.md`

**Output**: `docs/02_ARCHITECTURE.md`
- C4 Level 1 (System Context only)
- API endpoint list (no full OpenAPI spec)
- Data models (tables + key relationships)

**Time**: ~15 minutes

---

#### Step 3: Security (Lean)
**Prompt**: Use standard `prompts/03_security_compliance.md` but focus on:
- AuthN/AuthZ strategy
- Encryption at rest/transit
- Input validation
- Skip: Full STRIDE, compliance mapping

**Output**: `docs/03_SECURITY.md` (simplified)

**Time**: ~10 minutes

---

#### Step 4: Testing (Lean)
**Prompt**: `prompts/lean/04_testing_strategy.md`

**Output**: `docs/04_TESTING.md`
- Unit test strategy
- Integration test strategy
- Skip: E2E, performance, security testing

**Time**: ~10 minutes

---

#### Step 5: Implementation Plan (Lean)
**Prompt**: `prompts/lean/05_implementation_plan.md`

**Output**: `docs/05_IMPLEMENTATION.md`
- Task breakdown (focus on MVP features)
- Dependency order
- Skip: Detailed ADRs, rollback plans

**Time**: ~10 minutes

---

### Phase 2: Build Loop

Use the standard Antigravity agent workflow:
1. Point agent to `docs/05_IMPLEMENTATION.md`
2. Agent reads specs and builds features
3. Agent runs tests
4. Iterate

---

## When to Upgrade to Enterprise Mode

Switch to full Protocol v2.0 when:
- You're raising funding
- You need SOC2/HIPAA compliance
- Team grows beyond 5 people
- You're handling sensitive data (PII, PHI, financial)
- You need detailed audit trails

---

## Escape Hatches

### "I just want to prototype"
Skip Steps 3-4 entirely. Just do:
1. Requirements (Step 1)
2. Architecture (Step 2)
3. Build

### "I need to iterate mid-build"
- Update the relevant `docs/*.md` file
- Tell the agent: "Requirements changed, re-read docs/01_REQUIREMENTS.md"
- Continue building

### "This is taking too long"
- Use verbosity controls in prompts (select "Lightweight" when asked)
- Skip optional sections
- Focus on Must-Have features only

---

## Lean Mode Checklist

- [ ] Read this guide
- [ ] Run Step 1 (Requirements)
- [ ] Run Step 2 (Architecture)
- [ ] Run Step 3 (Security) - optional but recommended
- [ ] Run Step 4 (Testing) - optional but recommended
- [ ] Run Step 5 (Implementation Plan)
- [ ] Point IDE agent to `docs/05_IMPLEMENTATION.md`
- [ ] Build!

---

## Comparison: Lean vs Enterprise

| Aspect | Lean Mode | Enterprise Mode |
|--------|-----------|-----------------|
| **Artifacts** | ~10 docs | 25+ docs |
| **Time to Spec** | ~1 hour | ~4-6 hours |
| **C4 Diagrams** | Level 1 only | Levels 1-3 |
| **Threat Modeling** | Checklist | Full STRIDE tables |
| **Testing** | Unit + Integration | Full pyramid + perf + security |
| **Compliance** | None | SOC2, HIPAA, GDPR |
| **Best For** | MVPs, prototypes | Production, enterprises |

---

## Next Steps

1. Copy `prompts/lean/01_requirements_analysis.md` to your Web LLM
2. Paste your idea
3. Save the output to `docs/01_REQUIREMENTS.md`
4. Repeat for Steps 2-5
5. Start building!

**Need full rigor?** Switch to `prompts/00_MASTER_PROTOCOL.md` (Enterprise Mode)

```

## File: prompts/01_requirements_analysis.md
```md
Act as a Principal Product Manager operating under the "Antigravity" framework.

**Input:**
I have a rough idea for an application:
[INSERT YOUR IDEA HERE]

**Task:**
Analyze this idea and output a structured **Requirements Analysis** in Markdown.
Your goal is to produce a "Gold Standard" specification that could be handed to an enterprise engineering team.

**Output Format (01_REQUIREMENTS.md):**

# Requirements Analysis: [App Name]

## 1. Executive Summary
*   **Elevator Pitch**: One sentence value proposition.
*   **The Problem**: The specific friction or pain point being solved.
*   **The Solution**: The functional and emotional resolution.
*   **Target Audience**: Primary and secondary personas.

## 2. Feature Catalog (MoSCoW)
Group features by "Must Have", "Should Have", "Could Have", and "Won't Have".

### Must Have (MVP)
*   **[F-001] Feature Name**:
    *   **Description**: Detailed description of functionality.
    *   **User Benefit**: Why this matters to the user.
    *   **Acceptance Criteria**: Bullet points of what "done" looks like.

### Should Have (v1.1)
*   ...

## 3. Functional Requirements
For each "Must Have" feature, define the technical requirements:

| ID | Requirement | Input | Output | Validation Rule |
|----|-------------|-------|--------|-----------------|
| F-001-RQ-01 | System shall... | User clicks... | System displays... | Email must be unique |

## 4. Non-Functional Requirements
*   **Performance**: (e.g., <100ms API response, support 10k concurrent users).
*   **Security**: (e.g., MFA required, Data encrypted at rest).
*   **Compliance**: (e.g., GDPR, SOC2, HIPAA).
*   **Reliability**: (e.g., 99.9% uptime SLA).

## 5. User Stories
*   **US-001**: As a [Persona], I want to [Action], so that [Benefit].
    *   **Acceptance Criteria**: ...

```

## File: prompts/02_architecture_design.md
```md
Act as a Principal Software Architect.

**Input:**
I have provided the `01_REQUIREMENTS.md` for a new application.

**Task:**
Design the Technical Architecture for this product. Output a **Technical Blueprint** in Markdown.
Focus on scalability, security, and maintainability.

**Output Format (02_ARCHITECTURE.md):**

# Architecture Design

## 1. System Context (C4 Level 1)
*   **Diagram**: Mermaid diagram showing the system and its external dependencies (Users, External APIs, Legacy Systems).
*   **Description**: Narrative of the high-level interactions.

## 2. Container Architecture (C4 Level 2)
*   **Diagram**: Mermaid diagram showing the internal containers (Web App, API, Database, Worker, Cache).
*   **Technology Choices**:
    *   **Frontend**: (e.g., Next.js, React, Tailwind).
    *   **Backend**: (e.g., Node.js/NestJS, Python/FastAPI).
    *   **Database**: (e.g., PostgreSQL, MongoDB).
    *   **Infrastructure**: (e.g., AWS, Vercel, Docker).

## 3. Data Model
*   **ER Diagram**: Mermaid `erDiagram` showing entities and relationships.
*   **Schema Definition**: Brief description of key tables/collections and their purpose.

## 4. API Design
*   **Interface Definition**: High-level description of key API endpoints (REST or GraphQL).
    *   `GET /api/v1/resource`: Description.
    *   `POST /api/v1/resource`: Description.
*   **Integration Patterns**: How do services communicate? (Sync HTTP, Async Events/Kafka).

## 5. Cross-Cutting Concerns
*   **Observability**: Logging, Metrics, Tracing strategy.
*   **Error Handling**: Standardized error response format.
*   **Caching**: Strategy for read-heavy data (Redis, CDN).

```

## File: prompts/03_security_compliance.md
```md
Act as a Chief Information Security Officer (CISO).

**Input:**
I have provided the `01_REQUIREMENTS.md` and `02_ARCHITECTURE.md`.

**Task:**
Develop a comprehensive **Security & Compliance Strategy**.
Do not be generic. Be specific to the architecture and requirements defined.

**Output Format (03_SECURITY.md):**

# Security & Compliance Strategy

## 1. Threat Modeling (STRIDE)
Analyze the architecture for threats:
*   **Spoofing**: How do we prevent impersonation? (AuthN strategy).
*   **Tampering**: How do we ensure data integrity? (Signatures, Checksums).
*   **Repudiation**: How do we prove actions happened? (Audit Logs).
*   **Information Disclosure**: How do we prevent leaks? (Encryption, PII handling).
*   **Denial of Service**: How do we ensure availability? (Rate limiting, WAF).
*   **Elevation of Privilege**: How do we enforce permissions? (RBAC/ABAC).

## 2. Authentication & Authorization
*   **AuthN**: Identity Provider (Auth0, Cognito, Supabase Auth), MFA policy.
*   **AuthZ**: Role definitions, Permission matrix, Policy enforcement points.

## 3. Data Protection
*   **Data Classification**: Public, Internal, Confidential, Restricted.
*   **Encryption**:
    *   **At Rest**: Database encryption, Key management (KMS).
    *   **In Transit**: TLS 1.3, mTLS for internal services.

## 4. Compliance Controls
Map requirements to relevant standards (if applicable):
*   **SOC2**: Access controls, Change management.
*   **GDPR/CCPA**: Right to be forgotten, Data portability.
*   **HIPAA**: PHI handling (if healthcare related).

## 5. Secure Development Lifecycle (SDLC)
*   **Pre-commit**: Secret scanning, SAST (Static Analysis).
*   **CI/CD**: DAST (Dynamic Analysis), Dependency scanning (SCA).

```

## File: prompts/04_testing_strategy.md
```md
Act as a QA Lead / Test Architect.

**Input:**
I have provided the `01_REQUIREMENTS.md` and `02_ARCHITECTURE.md`.

**Task:**
Design a **Master Test Strategy** to ensure the system meets all functional and non-functional requirements.

**Output Format (04_TESTING.md):**

# Master Test Strategy

## 1. Test Pyramid Strategy
Define the scope and tools for each level:
*   **Unit Tests**: (Jest/Vitest) - Coverage target (e.g., 80%), mocking strategy.
*   **Integration Tests**: (Supertest/Testcontainers) - API contract verification, database interaction.
*   **E2E Tests**: (Playwright/Cypress) - Critical user journeys to automate.

## 2. Performance Testing
*   **Load Testing**: (k6/Gatling) - Scenarios to simulate (e.g., Black Friday traffic).
*   **Benchmarks**: Latency targets for key endpoints.

## 3. Security Testing
*   **SAST**: Tools to run in CI (e.g., SonarQube, CodeQL).
*   **DAST**: Automated vulnerability scanning (e.g., OWASP ZAP).

## 4. User Acceptance Testing (UAT)
*   **Plan**: How will stakeholders verify features?
*   **Beta Testing**: Strategy for phased rollout.

## 5. CI/CD Quality Gates
*   Define the conditions that must be met to merge code or deploy to production.
    *   e.g., "All tests pass", "Coverage > 80%", "No critical vulnerabilities".

```

## File: prompts/05_implementation_plan.md
```md
Act as a Technical Project Manager and Lead Engineer.

**Input:**
I have provided the full documentation suite:
1.  `01_REQUIREMENTS.md`
2.  `02_ARCHITECTURE.md`
3.  `03_SECURITY.md`
4.  `04_TESTING.md`

**Task:**
Synthesize these documents into a concrete **Implementation Plan** for an AI Agent (like Antigravity).
Break down the work into sequential, verifiable tasks.

**Output Format (05_IMPLEMENTATION.md):**

# Implementation Plan

## 1. Project Setup
*   [ ] Initialize repository with standard tooling (Linter, Formatter, Husky).
*   [ ] Configure CI/CD pipelines (GitHub Actions).
*   [ ] Set up infrastructure (Terraform/Docker).

## 2. Core Foundation
*   [ ] Implement Database Schema & Migrations.
*   [ ] Implement Authentication & Authorization module.
*   [ ] Implement Base API Structure (Health checks, Logging).

## 3. Feature Implementation (Iterative)
Group by Feature ID from Requirements:
*   **Feature [F-001]**:
    *   [ ] Backend: API endpoints.
    *   [ ] Frontend: UI Components.
    *   [ ] Tests: Unit & Integration.

## 4. Verification & Launch
*   [ ] Run full regression suite.
*   [ ] Perform security audit.
*   [ ] Deploy to Staging.
*   [ ] Smoke test Staging.
*   [ ] Promote to Production.

## 5. Agent Instructions (`task.md`)
Generate the initial `task.md` file content that the AI Agent will use to track progress.

```

## File: prompts/REDTEAM/gpt5-response.md
```md
Below is the **full Red-Team Audit** of your **Quantum Diamond Forge Protocol v2.0**, based directly on the complete v2 snapshot you provided in `redteam_snapshot_v2.txt` .

I‚Äôm treating this like an enterprise methodology review‚Äîno politeness, no euphemisms, just an honest audit of what works, what doesn‚Äôt, and what needs fixing before real teams adopt it.

---

# ‚≠ê **Executive Summary**

The QDF v2.0 protocol is a **dramatic upgrade** in structure and maturity over v1.0‚Äîespecially in its inclusion of professional-grade requirements engineering, C4 modeling, threat modeling, and testing discipline. However, the current prompts and workflow **over-index on rigor**, creating a process that is powerful but *fragile, heavy, and potentially unusable* for non-enterprise developers.

The biggest risks are:

* **Prompt bloat**
* **Unclear ownership boundaries**
* **High ceremony with low automation**
* **Maintenance unsustainability**

Overall: **Excellent foundation, but the cost-to-benefit ratio is not yet optimized.**

---

# ‚úÖ **Strengths**

### **1. Enterprise-Grade Scope & Artifacts**

QDF v2.0 includes:

* Formal requirements
* C4 diagrams
* API definition
* Data modeling
* Threat modeling
* Test strategy
  These are *exactly* the kinds of artifacts missing in most AI-driven workflows; the protocol brings much-needed discipline.

### **2. Clear Role Separation**

The 3-agent model is strong:

* Human = decider
* Web LLM = spec generator
* IDE Agent = implementer
  This maintains guardrails and mitigates hallucinations by preventing single-LLM authority.

### **3. Strong Emphasis on Security & Testing**

Unlike other frameworks, v2.0 actively pushes:

* Threat modeling
* AuthN/AuthZ strategy
* Test pyramid
* Performance considerations
  This is rare and valuable.

### **4. The Protocol Is Deterministic**

The step-by-step decomposition is tight:
1 ‚Üí 2 ‚Üí 3 ‚Üí 4 ‚Üí 5
Each step produces discrete artifacts, reducing drift.

---

# ‚ùå **Weaknesses**

Below are the critical failure points.

---

## **1. The Workflow Is Too Heavy for Real Developers**

Even senior engineers will not maintain:

* A full feature catalog
* Multiple C4 diagrams
* Complete threat model
* Test pyramid
* Detailed implementation plan

**It‚Äôs a 5-phase waterfall with 25+ artifacts.**
Solo developers and startups will bail.

---

## **2. Prompts Are Overly Dense and Brittle**

The v2 prompts rely on:

* Walls of text
* Nested instructions
* Multi-part artifacts

Large prompts get misinterpreted by LLMs, especially when structure is strict.
This causes:

* Hallucinated sections
* Missing subsections
* Formatting drift
* Overwriting of prior parts

LLM robustness decreases as prompt length ‚Üí increases.

---

## **3. No Mechanism to Keep Artifacts in Sync**

QDF v2.0 still assumes:

* Requirements won't change
* Architectural designs won't change
* API specs won't change

But real projects evolve.

There is **no sync mechanism** such as:

* Blueprint lockfiles
* Incremental diffs
* Semantic versioning of specs
* Cross-file validation

This guarantees drift.

---

## **4. LLM Context & Cognitive Load Problems**

You‚Äôre asking the Web LLM to:

* Hold the Feature Catalog
* Hold the architecture
* Hold threat models
* Hold test strategy
* Hold implementation plan

This is too much; it will compress context and begin dropping details after ~20 steps.

Result:

* Inconsistencies
* Violated requirements
* Mismatched names

IDE Agents will drift further.

---

## **5. The Protocol Lacks ‚ÄúEscape Hatches‚Äù**

There are no instructions for:

* When a developer wants to skip a step
* When they want to iterate quickly
* When they only need a partial artifact
* When specs need revisions mid-implementation

Rigid systems break easily.

---

## **6. Security Is Suggested but Not Enforced**

Threat modeling is included, but:

* No tooling
* No validation
* No automated checks

Developers won‚Äôt manually update STRIDE tables.

Thus:
**Security theater instead of security guarantees.**

---

## **7. Burden on the Human-in-the-Loop**

The human is expected to:

* Provide vision
* Approve decisions
* Validate artifacts
* Navigate huge text dumps
* Detect inconsistencies manually

This is *too much cognitive overhead*.

---

# üõ†Ô∏è **Recommendations**

Here are the specific, actionable upgrades.

---

## ‚≠ê **1. Introduce a Two-Track Workflow**

**Enterprise Track**
Full 5-phase process for large products.

**Lean Track**
For solo devs and prototypes:

* No C4 level 2‚Äì3
* No threat modeling tables
* Reduced requirements structure
* Test strategy limited to unit + integration

Let the user decide the rigor level.

---

## ‚≠ê **2. Replace Giant Prompts With Modular ‚ÄúPrompt Modules‚Äù**

Instead of one massive Phase 1 or Phase 2 prompt, create:

* `/prompts/modules/requirements.md`
* `/prompts/modules/architecture.md`
* `/prompts/modules/security.md`

Each module is:

* Short
* Robust
* Easier for LLMs to follow
* Easier to maintain

IDE Agents consume modules selectively.

---

## ‚≠ê **3. Add a ‚ÄúSpec Lockfile‚Äù System**

Inspired by package lockfiles:

* `requirements.lock.json`
* `architecture.lock.json`
* `security.lock.json`

Every run of the Web LLM updates or revalidates these lockfiles.
IDE Agents read *only lockfiles*, not raw prompts.

This solves drift.

---

## ‚≠ê **4. Add a ‚ÄúDiff & Validate‚Äù Step**

Before the IDE Agent builds features, run:

```
QDF validate
```

It checks:

* Data models match API
* API matches C4
* Threat model references actual endpoints
* Test plan covers critical features

This is deterministic and prevents spec rot.

---

## ‚≠ê **5. Introduce Iteration Protocols**

Right now QDF v2.0 is strictly linear.

Add:

* `QDF revise requirements`
* `QDF revise architecture`
* `QDF revise security`
* `QDF revise testplan`

Each revision re-generates:

* Diffs
* Lockfile updates
* ‚ÄúBreaking changes‚Äù lists

---

## ‚≠ê **6. Add ‚ÄúHuman Effort Controls‚Äù**

Prompts should ask:

> ‚ÄúDo you want full detail, medium detail, or a lightweight summary?‚Äù

This lets the human modulate output verbosity.

---

## ‚≠ê **7. Add Automation Layers**

Provide optional scripts to:

* Lint requirements
* Validate C4 diagrams
* Check for missing test cases
* Auto-generate coverage reports

This shifts burden off the developer.

---

# üî• **Risk Assessment**

### **Major Risks**

1. **Developer abandonment** (workflow too heavy)
2. **LLM drift** (context overload)
3. **Stale specs** (no sync mechanism)
4. **Security gaps** (artifacts with no enforcement)
5. **Prompt brittleness** (mega-prompts unreliable)
6. **Human burnout** (too many artifacts)
7. **Lack of iteration support** (protocol breaks under change)

### **Biggest Threat**

**The protocol optimizes for rigor at the expense of velocity and practicality.**
Without stronger automation and simplification, QDF v2.0 risks becoming a documentation generator rather than a productivity booster.

---

# ‚úîÔ∏è If you want, I can now generate:

* A **rewritten QDF v2.1** with all these improvements
* A **Lean Track variant** for fast-moving solo developers
* A **Spec Lockfile system**
* A **Validation & Drift Checker**
* A **Modular prompt architecture**
* Or a **diagram of the improved workflow**

Just say:
**‚ÄúGenerate the v2.1 protocol with improvements.‚Äù**

```

## File: prompts/REDTEAM/grok4-response.md
```md
### Executive Summary
Quantum Diamond Forge v2.0 represents a solid evolution from its lightweight predecessor, introducing a structured, enterprise-inspired workflow that enforces rigor through phased prompts and human oversight, making it suitable for mid-scale projects aiming for production readiness. However, it remains overly bureaucratic and fragmented, with excessive manual steps that undermine developer efficiency and risk low adoption among solo or agile teams. While it addresses v1's fragility, it swings too far toward over-engineering, potentially stifling the "speed" promised in AI-native development.

### Strengths
- **Comprehensive Coverage of Enterprise Essentials:** The 5-step workflow effectively mirrors industry standards like those from AWS Well-Architected or Google's SRE practices, incorporating threat modeling (STRIDE), test pyramids, C4 diagrams, and ADRs. This ensures outputs are not just prototypes but robust blueprints, with strong emphasis on security and compliance from the outset‚Äîe.g., the Security prompt's focus on encryption and SDLC controls is practical and actionable.
- **Human-in-the-Loop Balance:** By positioning the human as orchestrator, it mitigates AI hallucinations through review gates, while leveraging web LLMs for heavy lifting. The CLI tools (forge.sh) add convenience for governance, like automated task/ADR creation and git hooks, enhancing maintainability without full automation overload.
- **Modular and Extensible Design:** Prompts are self-contained yet chainable, with clear inputs/outputs (e.g., attaching prior docs). The Expert Council and Inbox workflow provide flexibility for deep dives or iterations, and CI/CD guides ground the protocol in real-world ops.
- **Focus on Developer Experience:** Features like code snapshots and conventional commits promote clean habits, and the diagrams (Mermaid) aid visualization, making complex architectures accessible.

### Weaknesses
- **Workflow Fragmentation and Manual Overhead:** The process relies on tedious copy-paste between CLI, web LLMs, and IDE agents, with no integrated tooling for automation (e.g., no API wrappers for LLMs). This creates friction‚Äîe.g., saving outputs as separate MD files invites version mismatches or lost context, and the "Review the Output" step assumes flawless human judgment without checklists.
- **Over-Engineering for Broad Use Cases:** Prompts enforce enterprise artifacts (e.g., full STRIDE models, SOC2 mappings) even for simple apps, bloating small projects. Non-functional requirements like "99.9% uptime" are aspirational but impractical without cost analysis. Edge cases like hybrid mobile/web apps, real-time features (e.g., WebSockets), or international compliance (e.g., non-GDPR regions) are underexplored.
- **Usability Barriers for Solos:** The protocol assumes familiarity with tools like Mermaid, Husky, or Terraform, overwhelming beginners. Prompts are verbose and prescriptive, limiting creativity‚Äîe.g., fixed formats (MoSCoW, C4) might not fit all domains. The "Antigravity Loop" in execution feels vague, with no explicit error recovery if LLM outputs diverge.
- **Blind Spots in AI Integration:** Assumptions that web LLMs (e.g., Gemini/Claude) consistently produce "Gold Standard" specs ignore variability in responses. No mechanisms for prompt versioning or A/B testing LLMs. Practicality suffers from artifact heaviness‚Äîmaintaining 5+ MD files plus TASKS/ADRS could lead to outdated docs, especially without auto-sync tools.
- **Limited Scope and Assumptions:** Optimizes for backend-heavy web apps (e.g., Next.js/PostgreSQL stacks), neglecting frontend-heavy or no-code scenarios. Risks include LLM dependency (what if APIs change?) and no built-in metrics for protocol efficacy (e.g., time-to-deploy benchmarks).

### Recommendations
- **Streamline Orchestration:** Integrate a unified CLI command (e.g., `./forge.sh run-phase 1`) that automates pasting to LLMs via APIs (if available) or clipboard managers, and auto-saves outputs with versioning (e.g., git commits). Add a "lite mode" flag to skip non-essentials like full compliance for MVPs.
- **Enhance Completeness with Templates and Checks:** Include prompt refinements for edge cases‚Äîe.g., add sections in Architecture prompt for scalability (auto-scaling rules) and deployment (Kubernetes vs. serverless). Introduce validation scripts (e.g., `./forge.sh validate-spec`) that check artifacts for consistency (e.g., ensuring API designs match data models).
- **Improve Usability and Pragmatism:** Shorten prompts by 30% with modular sections (e.g., optional "Advanced" blocks for enterprise features). Provide starter templates in repo for common stacks, and add a "feedback loop" prompt in Implementation Plan to iterate on specs mid-build. For solos, bundle a quick-start script that generates a minimal workflow.
- **Address Practicality Barriers:** Lighten artifacts by consolidating into a single "Master Spec" MD with sections, using tools like Notion exporters for easier maintenance. Lower adoption hurdles with video tutorials in README and community examples. Track usage via optional telemetry in CLI to iterate on the protocol itself.
- **Mitigate Blind Spots:** Explicitly document assumptions (e.g., "Assumes stable LLM access") in GUIDE.md. Add a "Post-Implementation Review" phase with prompts for auditing drift (e.g., code vs. specs). Optimize for agility by allowing parallel phases (e.g., start coding while security refines) and include cost/benefit analyses in prompts.

### Risk Assessment
The biggest threat to adoption is developer fatigue from the manual, multi-tool workflow‚Äîsolo devs might abandon it after Phase 2 for simpler tools like Cursor or Replit AI, leading to niche use in enterprises only. What could fail: Inconsistent LLM outputs causing spec drift, amplified by weak human review; or over-reliance on git hooks leading to blocked workflows in fast-iterating teams. Overall, the protocol risks becoming a "shelfware" artifact‚Äîrigorous but unused‚Äîif not balanced with more automation, as it optimizes for perfection at the expense of iteration speed in an AI era where prototypes evolve rapidly.
```

## File: prompts/REDTEAM/redteam_analysis.md
```md
# Red Team Analysis: Quantum Diamond Forge Protocol v2.0

## Your Role
You are an **Independent Protocol Auditor** with expertise in:
- Software development methodologies
- AI-assisted development workflows
- Enterprise software architecture
- Developer experience (DX) design

## Context
The Quantum Diamond Forge (QDF) is a protocol for building production-ready software using AI agents. It recently underwent a major upgrade from v2.0 to v2.1 based on red team feedback.

**What Changed from v2.0 to v2.1:**
- **Two-Track Workflow**: Added "Lean" mode for MVPs (~1 hour) alongside "Enterprise" mode (~4-6 hours)
- **Modular Prompts**: Broke monolithic prompts into focused modules (60-70% shorter)
- **Improved DX**: Reduced artifacts from 25+ to ~10 for Lean mode

**The v2.1 Lean Workflow:**
1. **Requirements Analysis** ‚Üí Feature Catalog (Must-Have only), 3-5 User Stories
2. **Architecture Design** ‚Üí C4 Level 1, Simple API list, Data Models
3. **Security** ‚Üí Basic AuthN/AuthZ, Encryption checklist (no full STRIDE)
4. **Testing Strategy** ‚Üí Unit + Integration only (no E2E/perf)
5. **Implementation Plan** ‚Üí MVP task breakdown

**The v2.1 Enterprise Workflow:**
- Same as v2.0 but now with modular prompts for better reliability

**The Orchestration Model:**
- **Human** provides vision and decisions
- **Web LLM** (Gemini/Claude) generates rigorous specs from prompts
- **IDE Agent** (Antigravity) implements code based on specs

## Your Task
Analyze the attached Protocol v2.0 snapshot and provide a **critical, constructive review**.

### Analysis Framework

#### 1. Completeness
- Are there gaps in the workflow?
- What's missing from the prompts?
- Are there edge cases not covered?

#### 2. Usability
- Is this too complex for solo developers?
- Will the "Human-in-the-Loop" model create friction?
- Are the prompts clear and actionable?

#### 3. Rigor vs. Pragmatism
- Does it match enterprise standards?
- Is it over-engineered for typical projects?
- What's the right balance?

#### 4. Practicality
- Will developers actually use this workflow?
- Are the artifacts too heavy to maintain?
- What are the adoption barriers?

#### 5. Blind Spots
- What assumptions are we making?
- What could go wrong?
- What are we optimizing for at the expense of what?

## Output Format

Please structure your response as:

### Executive Summary
[2-3 sentences: Overall assessment]

### Strengths
[What v2 does well]

### Weaknesses
[Critical gaps and concerns]

### Recommendations
[Specific, actionable improvements]

### Risk Assessment
[What could fail? What's the biggest threat to adoption?]

---

**Be brutally honest.** We want to find flaws before users do.

```

## File: prompts/REDTEAM/synthesis.md
```md
# Red Team Analysis Synthesis

**Date**: 2025-11-22  
**Reviewers**: GPT-5, Grok 4  
**Protocol Version**: v2.0

## Executive Summary

Both reviewers agree: **Protocol v2.0 is a dramatic improvement over v1**, bringing enterprise-grade rigor and structure. However, **it over-indexes on ceremony at the expense of velocity**, creating a workflow that is powerful but potentially unusable for solo developers and small teams.

### Consensus Assessment
- ‚úÖ **Foundation is excellent** (C4, STRIDE, test pyramids, ADRs)
- ‚ö†Ô∏è **Execution is too heavy** (25+ artifacts, manual copy-paste, no automation)
- üî¥ **Critical Risk**: Developer abandonment due to cognitive overload

---

## Common Themes

### üéØ Strengths (Both Agree)
1. **Enterprise-grade artifacts** - Formal requirements, C4 diagrams, threat modeling, test strategy
2. **Human-in-the-loop model** - Mitigates AI hallucinations through review gates
3. **Security-first approach** - STRIDE, AuthN/AuthZ, encryption strategies
4. **Deterministic workflow** - Clear 5-step process reduces drift
5. **Modular design** - Prompts are chainable with clear inputs/outputs

### ‚ùå Weaknesses (Both Agree)

#### 1. **Workflow Too Heavy**
- GPT-5: "5-phase waterfall with 25+ artifacts. Solo developers will bail."
- Grok 4: "Overly bureaucratic... excessive manual steps undermine efficiency."

**Impact**: High abandonment risk for non-enterprise users.

#### 2. **Prompt Bloat & Brittleness**
- GPT-5: "Walls of text... LLM robustness decreases as prompt length increases."
- Grok 4: "Prompts are verbose and prescriptive, limiting creativity."

**Impact**: Hallucinated sections, formatting drift, missing subsections.

#### 3. **No Sync Mechanism**
- GPT-5: "No blueprint lockfiles, incremental diffs, or cross-file validation."
- Grok 4: "Maintaining 5+ MD files... could lead to outdated docs."

**Impact**: Guaranteed spec drift as projects evolve.

#### 4. **Manual Overhead**
- GPT-5: "Tedious copy-paste... too much cognitive overhead."
- Grok 4: "No integrated tooling... saving outputs as separate MD files invites version mismatches."

**Impact**: Developer fatigue, human error.

#### 5. **No Escape Hatches**
- GPT-5: "No instructions for skipping steps, iterating quickly, or partial artifacts."
- Grok 4: "No explicit error recovery if LLM outputs diverge."

**Impact**: Rigid system breaks under real-world pressure.

#### 6. **Security Theater**
- GPT-5: "Threat modeling included, but no tooling, validation, or automated checks."
- Grok 4: "Assumes flawless human judgment without checklists."

**Impact**: Security artifacts exist but aren't enforced.

---

## Top Recommendations (Prioritized)

### üî• Critical (Must-Have for v2.1)

#### 1. **Two-Track Workflow**
**Source**: GPT-5, Grok 4  
**What**: Create "Enterprise" and "Lean" tracks
- **Lean**: Skip C4 level 2-3, threat tables, reduce requirements
- **Enterprise**: Full 5-phase process

**Why**: Prevents solo dev abandonment while preserving rigor for teams.

#### 2. **Modular Prompts**
**Source**: GPT-5, Grok 4  
**What**: Break prompts into `/prompts/modules/` (requirements, architecture, security)
- Each module: short, robust, easier for LLMs
- Reduce prompt length by 30%

**Why**: Reduces hallucinations, improves maintainability.

#### 3. **Spec Lockfile System**
**Source**: GPT-5  
**What**: Introduce `requirements.lock.json`, `architecture.lock.json`
- IDE agents read lockfiles, not raw prompts
- Versioned, diffable, prevents drift

**Why**: Solves the #1 technical debt issue.

### ‚ö†Ô∏è High Priority (Should-Have)

#### 4. **Validation & Diff Tools**
**Source**: GPT-5, Grok 4  
**What**: `./forge.sh validate` command
- Checks: data models match API, threat model references real endpoints
- Lints requirements, validates C4 diagrams

**Why**: Shifts burden from human to automation.

#### 5. **Iteration Support**
**Source**: GPT-5, Grok 4  
**What**: Add `./forge.sh revise <phase>` commands
- Generates diffs, lockfile updates, breaking changes lists
- Supports mid-implementation spec changes

**Why**: Real projects evolve; protocol must support iteration.

#### 6. **CLI Automation**
**Source**: Grok 4  
**What**: `./forge.sh run-phase 1` with API wrappers or clipboard automation
- Auto-saves outputs with git versioning
- Adds "lite mode" flag

**Why**: Reduces manual copy-paste friction.

### üí° Nice-to-Have

#### 7. **Human Effort Controls**
**Source**: GPT-5  
**What**: Prompts ask: "Full detail, medium, or lightweight?"
- Modulates output verbosity

**Why**: Reduces cognitive load.

#### 8. **Starter Templates**
**Source**: Grok 4  
**What**: Pre-built templates for common stacks (Next.js/Supabase, etc.)

**Why**: Lowers adoption barriers.

---

## Risk Assessment

### Biggest Threat (Both Agree)
**"Developer abandonment due to workflow heaviness."**

- GPT-5: "Risks becoming a documentation generator rather than productivity booster."
- Grok 4: "Solo devs might abandon after Phase 2 for simpler tools like Cursor."

### What Could Fail
1. **Inconsistent LLM outputs** ‚Üí Spec drift (amplified by weak human review)
2. **Over-reliance on git hooks** ‚Üí Blocked workflows in fast-iterating teams
3. **Artifact maintenance burden** ‚Üí Outdated docs, "shelfware" protocol

---

## Next Steps

I recommend creating the following tasks:

1. **Task 003**: Design Two-Track Workflow (Lean vs Enterprise)
2. **Task 004**: Implement Modular Prompt Architecture
3. **Task 005**: Design Spec Lockfile System
4. **Task 006**: Build Validation & Diff Tooling
5. **Task 007**: Add Iteration Support (`revise` commands)

**Priority**: Start with Tasks 003 and 004 (Two-Track + Modular Prompts) as they address the most critical feedback.

```

## File: prompts/lean/01_requirements_analysis.md
```md
# Requirements Analysis (Lean Mode)

## Your Role
You are a **Product Analyst** helping a solo developer or small team build an MVP. Focus on **essential features** and **clear user stories** without excessive ceremony.

## Context
The user has an idea for a software product. Your job is to help them define:
1. **What** they're building (feature catalog)
2. **Who** it's for (user stories)
3. **How** to validate it (acceptance criteria)

Keep it **lean and actionable**‚Äîthis is an MVP, not an enterprise product.

## Input
The user will provide:
- A brief description of their idea
- Target users (if known)
- Key problems they're solving

## Your Task

Generate a **Requirements Document** with the following structure:

---

### 1. Product Overview
**Format**:
```
## Product Overview

**Name**: [Product Name]
**Tagline**: [One-line description]
**Problem**: [What problem does this solve?]
**Solution**: [How does this product solve it?]
```

Keep this to 3-4 sentences total.

---

### 2. Feature Catalog (MoSCoW - Lean)
**Format**:
```
## Feature Catalog

### Must-Have (MVP Core)
1. [Feature Name]: [1-sentence description]
2. [Feature Name]: [1-sentence description]
...

### Should-Have (Post-MVP)
1. [Feature Name]: [1-sentence description]
2. [Feature Name]: [1-sentence description]
...
```

**Rules**:
- **Must-Have**: 3-7 features max (the absolute minimum for a working product)
- **Should-Have**: 3-5 features (nice-to-haves for v1.1)
- **Skip**: Could-Have and Won't-Have (not needed for MVP)

---

### 3. User Stories (Top 3-5 Only)
**Format**:
```
## User Stories

### US-001: [Story Title]
**As a** [user type]  
**I want** [action]  
**So that** [benefit]

**Acceptance Criteria**:
- [ ] [Specific, testable criterion]
- [ ] [Specific, testable criterion]

---

### US-002: [Story Title]
...
```

**Rules**:
- Write **3-5 stories** covering the Must-Have features
- Each story should have **2-4 acceptance criteria**
- Keep criteria **simple and testable**

---

### 4. Non-Functional Requirements (Essentials Only)
**Format**:
```
## Non-Functional Requirements

### Performance
- [1-2 key metrics, e.g., "Page load < 2s"]

### Security
- [1-2 essentials, e.g., "HTTPS only", "Password hashing"]

### Scalability
- [1 sentence on expected load, e.g., "Support 100 concurrent users"]
```

**Rules**:
- **Skip**: Detailed SLAs, compliance requirements, extensive monitoring
- **Keep**: Basic performance, security, and scalability expectations

---

## Output Format

Provide the complete document in **Markdown** format, ready to save as `docs/01_REQUIREMENTS.md`.

---

## Example Output

```markdown
# Requirements Document (Lean)

## Product Overview

**Name**: TaskFlow  
**Tagline**: Simple task management for solo developers  
**Problem**: Developers need a lightweight way to track tasks without complex project management tools.  
**Solution**: A minimal task board with drag-and-drop, markdown support, and GitHub integration.

## Feature Catalog

### Must-Have (MVP Core)
1. **Task Board**: Kanban-style board with To Do, In Progress, Done columns
2. **Markdown Tasks**: Create tasks with markdown descriptions
3. **Drag & Drop**: Move tasks between columns
4. **GitHub Sync**: Import issues from GitHub repos
5. **Local Storage**: Save tasks in browser (no backend needed for MVP)

### Should-Have (Post-MVP)
1. **Tags & Filters**: Organize tasks by tags
2. **Due Dates**: Set deadlines for tasks
3. **Cloud Sync**: Save tasks to a backend for multi-device access

## User Stories

### US-001: Create a Task
**As a** developer  
**I want** to create a task with a title and markdown description  
**So that** I can track what I need to do

**Acceptance Criteria**:
- [ ] User can click "New Task" button
- [ ] User can enter title and markdown description
- [ ] Task appears in "To Do" column

---

### US-002: Move Tasks Between Columns
**As a** developer  
**I want** to drag tasks between columns  
**So that** I can update task status visually

**Acceptance Criteria**:
- [ ] User can drag a task from one column to another
- [ ] Task position updates immediately
- [ ] Changes persist in local storage

---

### US-003: Import GitHub Issues
**As a** developer  
**I want** to import issues from my GitHub repo  
**So that** I don't have to manually recreate tasks

**Acceptance Criteria**:
- [ ] User can enter GitHub repo URL
- [ ] System fetches open issues via GitHub API
- [ ] Issues appear as tasks in "To Do" column

## Non-Functional Requirements

### Performance
- Page load < 2 seconds
- Drag-and-drop feels instant (< 100ms)

### Security
- HTTPS only
- GitHub OAuth for API access

### Scalability
- Support 500 tasks per board
- Handle 10 concurrent users (for future cloud sync)
```

---

## Important Notes

- **Be concise**: This is Lean mode‚Äîno walls of text
- **Focus on MVP**: Only include features needed for a working v1.0
- **Skip enterprise artifacts**: No detailed compliance, no extensive NFRs
- **Make it actionable**: Every feature should be clear enough to build

---

## Ready?

Paste the user's idea below, and I'll generate the lean requirements document.

```

## File: prompts/lean/02_architecture_design.md
```md
# Architecture Design (Lean Mode)

## Your Role
You are a **Software Architect** helping design an MVP. Focus on **essential architecture** without over-engineering.

## Context
The user has defined their requirements. Your job is to design:
1. **System Context** (C4 Level 1 only)
2. **API Endpoints** (simple list, not full OpenAPI)
3. **Data Models** (tables + key relationships)

Keep it **lean and buildable**‚Äîthis is an MVP, not a microservices architecture.

## Input
Attach the `docs/01_REQUIREMENTS.md` file from the previous step.

## Your Task

Generate an **Architecture Document** with the following structure:

---

### 1. System Context (C4 Level 1)
**Format**:
```
## System Context Diagram

\`\`\`mermaid
C4Context
    title System Context - [Product Name]
    
    Person(user, "User", "End user of the system")
    System(app, "[Product Name]", "Core application")
    System_Ext(external, "[External System]", "Description")
    
    Rel(user, app, "Uses")
    Rel(app, external, "Integrates with")
\`\`\`

**Key Components**:
- **[Product Name]**: [1-sentence description]
- **[External System]**: [1-sentence description]
```

**Rules**:
- Show **only** the main system and key external dependencies
- **Skip**: Container diagrams (C4 Level 2), Component diagrams (C4 Level 3)

---

### 2. Technology Stack
**Format**:
```
## Technology Stack

### Frontend
- **Framework**: [e.g., React, Vue, vanilla JS]
- **Styling**: [e.g., Tailwind, CSS]

### Backend
- **Runtime**: [e.g., Node.js, Python]
- **Framework**: [e.g., Express, FastAPI]
- **Database**: [e.g., PostgreSQL, SQLite]

### Deployment
- **Hosting**: [e.g., Vercel, Railway, local]
```

**Rules**:
- Choose **simple, proven** technologies
- Prefer **managed services** over self-hosted (e.g., Supabase over self-hosted Postgres)
- **Skip**: Detailed infrastructure diagrams, Kubernetes, microservices

---

### 3. API Design (Endpoint List)
**Format**:
```
## API Endpoints

### Tasks
- `GET /api/tasks` - List all tasks
- `POST /api/tasks` - Create a new task
- `PATCH /api/tasks/:id` - Update a task
- `DELETE /api/tasks/:id` - Delete a task

### Users
- `POST /api/auth/login` - User login
- `POST /api/auth/logout` - User logout
```

**Rules**:
- List **only** the core endpoints needed for MVP
- Use **RESTful** conventions
- **Skip**: Full OpenAPI spec, detailed request/response schemas

---

### 4. Data Models
**Format**:
```
## Data Models

### Table: users
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PRIMARY KEY |
| email | VARCHAR(255) | UNIQUE, NOT NULL |
| password_hash | VARCHAR(255) | NOT NULL |
| created_at | TIMESTAMP | DEFAULT NOW() |

### Table: tasks
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PRIMARY KEY |
| user_id | UUID | FOREIGN KEY (users.id) |
| title | VARCHAR(255) | NOT NULL |
| description | TEXT | |
| status | ENUM | 'todo', 'in_progress', 'done' |
| created_at | TIMESTAMP | DEFAULT NOW() |

**Relationships**:
- `tasks.user_id` ‚Üí `users.id` (many-to-one)
```

**Rules**:
- Show **only** the core tables needed for MVP
- Include **primary keys, foreign keys, and essential constraints**
- **Skip**: Detailed indexes, triggers, stored procedures

---

## Output Format

Provide the complete document in **Markdown** format, ready to save as `docs/02_ARCHITECTURE.md`.

---

## Important Notes

- **Be pragmatic**: Choose boring, proven tech over cutting-edge
- **Avoid over-engineering**: No microservices, no Kubernetes, no event sourcing
- **Focus on MVP**: Design for 100 users, not 1 million
- **Keep it simple**: If you can do it with a single database table, do it

---

## Ready?

Paste the requirements document below, and I'll generate the lean architecture.

```

## File: prompts/lean/04_testing_strategy.md
```md
# Testing Strategy (Lean Mode)

## Your Role
You are a **QA Engineer** helping define a practical testing strategy for an MVP. Focus on **essential tests** without excessive coverage.

## Context
The user has defined requirements and architecture. Your job is to define:
1. **Unit Test Strategy** (test core logic)
2. **Integration Test Strategy** (test API endpoints)
3. **Manual Testing Checklist** (for features that are hard to automate)

Keep it **lean and practical**‚Äîthis is an MVP, not a safety-critical system.

## Input
Attach the `docs/01_REQUIREMENTS.md` and `docs/02_ARCHITECTURE.md` files.

## Your Task

Generate a **Testing Strategy Document** with the following structure:

---

### 1. Testing Philosophy
**Format**:
```
## Testing Philosophy

For this MVP, we focus on:
- **Unit Tests**: Core business logic and utilities
- **Integration Tests**: API endpoints and database interactions
- **Manual Testing**: UI flows and edge cases

**What We Skip** (for now):
- E2E tests (too slow for MVP iteration)
- Performance tests (optimize later)
- Security tests (basic security in code review)
```

---

### 2. Unit Test Strategy
**Format**:
```
## Unit Tests

### What to Test
- [ ] [Business logic function 1]
- [ ] [Business logic function 2]
- [ ] [Utility function 1]

### Example Test Cases
**Function**: `validateEmail(email)`
- ‚úÖ Valid email: `test@example.com` ‚Üí `true`
- ‚úÖ Invalid email: `notanemail` ‚Üí `false`
- ‚úÖ Empty string: `""` ‚Üí `false`

**Coverage Goal**: 70% of core logic
```

**Rules**:
- List **5-10** key functions to unit test
- Provide **2-3 example test cases** for the most critical function
- **Skip**: 100% coverage, testing trivial getters/setters

---

### 3. Integration Test Strategy
**Format**:
```
## Integration Tests

### API Endpoints to Test
- [ ] `POST /api/tasks` - Create task
- [ ] `GET /api/tasks` - List tasks
- [ ] `PATCH /api/tasks/:id` - Update task
- [ ] `DELETE /api/tasks/:id` - Delete task

### Example Test Case
**Endpoint**: `POST /api/tasks`
- **Setup**: Create a test user
- **Request**: `{ "title": "Test Task", "description": "..." }`
- **Expected**: 201 Created, task appears in database
- **Teardown**: Delete test user and task

**Coverage Goal**: All core API endpoints
```

**Rules**:
- Test **all** core API endpoints from the architecture doc
- Provide **1 detailed example** test case
- **Skip**: Testing every edge case, load testing

---

### 4. Manual Testing Checklist
**Format**:
```
## Manual Testing Checklist

### Pre-Release Checklist
- [ ] User can sign up and log in
- [ ] User can create a task
- [ ] User can drag task between columns
- [ ] User can delete a task
- [ ] UI looks good on mobile
- [ ] UI looks good on desktop

### Edge Cases to Verify
- [ ] What happens if user creates 100 tasks?
- [ ] What happens if task title is very long?
- [ ] What happens if user loses internet connection?
```

**Rules**:
- List **5-10** critical user flows
- Include **3-5** edge cases to manually verify
- **Skip**: Exhaustive test matrices

---

## Output Format

Provide the complete document in **Markdown** format, ready to save as `docs/04_TESTING.md`.

---

## Important Notes

- **Be practical**: Focus on tests that catch real bugs
- **Avoid perfectionism**: 70% coverage is fine for an MVP
- **Manual testing is OK**: Not everything needs to be automated
- **Iterate**: Add more tests as the product matures

---

## Ready?

Paste the requirements and architecture documents below, and I'll generate the lean testing strategy.

```

## File: prompts/lean/05_implementation_plan.md
```md
# Implementation Plan (Lean Mode)

## Your Role
You are a **Technical Lead** helping break down an MVP into actionable tasks. Focus on **getting to a working v1.0 quickly**.

## Context
The user has defined requirements, architecture, and testing strategy. Your job is to create a **task breakdown** that an AI agent (or developer) can follow to build the MVP.

Keep it **lean and actionable**‚Äîthis is an MVP, not a 6-month project.

## Input
Attach all previous documents:
- `docs/01_REQUIREMENTS.md`
- `docs/02_ARCHITECTURE.md`
- `docs/04_TESTING.md`

## Your Task

Generate an **Implementation Plan** with the following structure:

---

### 1. Implementation Phases
**Format**:
```
## Implementation Phases

### Phase 1: Foundation (Week 1)
- Set up project structure
- Configure database
- Implement authentication

### Phase 2: Core Features (Week 2)
- Build task CRUD API
- Implement task board UI
- Add drag-and-drop

### Phase 3: Polish (Week 3)
- Add tests
- Fix bugs
- Deploy to production
```

**Rules**:
- Break into **3-4 phases** max
- Each phase should be **1-2 weeks** of work
- Focus on **Must-Have** features only

---

### 2. Task Breakdown
**Format**:
```
## Task Breakdown

### Phase 1: Foundation

#### Task 1.1: Project Setup
**Description**: Initialize project with chosen tech stack
**Deliverables**:
- [ ] Create Next.js app
- [ ] Set up Tailwind CSS
- [ ] Configure ESLint and Prettier

**Estimated Time**: 2 hours

---

#### Task 1.2: Database Setup
**Description**: Set up PostgreSQL database and ORM
**Deliverables**:
- [ ] Create Supabase project
- [ ] Define `users` and `tasks` tables
- [ ] Test database connection

**Estimated Time**: 3 hours

---

### Phase 2: Core Features

#### Task 2.1: Task CRUD API
**Description**: Implement API endpoints for task management
**Deliverables**:
- [ ] `POST /api/tasks` - Create task
- [ ] `GET /api/tasks` - List tasks
- [ ] `PATCH /api/tasks/:id` - Update task
- [ ] `DELETE /api/tasks/:id` - Delete task

**Estimated Time**: 6 hours
```

**Rules**:
- Each task should be **2-8 hours** of work
- Include **clear deliverables** (checkboxes)
- Provide **time estimates**
- Order tasks by **dependency** (foundation first)

---

### 3. Dependency Graph
**Format**:
```
## Dependency Graph

\`\`\`mermaid
graph TD
    T1[Task 1.1: Project Setup] --> T2[Task 1.2: Database Setup]
    T2 --> T3[Task 2.1: Task CRUD API]
    T3 --> T4[Task 2.2: Task Board UI]
    T4 --> T5[Task 2.3: Drag & Drop]
\`\`\`
```

**Rules**:
- Show **critical path** dependencies
- **Skip**: Complex dependency matrices

---

### 4. MVP Checklist
**Format**:
```
## MVP Checklist

### Must-Have Before Launch
- [ ] User can sign up and log in
- [ ] User can create, edit, delete tasks
- [ ] User can drag tasks between columns
- [ ] Basic tests pass
- [ ] Deployed to production

### Nice-to-Have (Post-Launch)
- [ ] Tags and filters
- [ ] Due dates
- [ ] Cloud sync
```

---

## Output Format

Provide the complete document in **Markdown** format, ready to save as `docs/05_IMPLEMENTATION.md`.

---

## Important Notes

- **Be realistic**: Don't underestimate time
- **Focus on MVP**: Only include Must-Have features
- **Make it actionable**: Each task should be clear enough to start immediately
- **Order matters**: Dependencies should be obvious

---

## Ready?

Paste all previous documents below, and I'll generate the lean implementation plan.

```

## File: prompts/lean/TEST_SCENARIO.md
```md
# Lean Mode Test Scenario

## Test Idea
**Product**: "QuickPoll" - A simple polling app for teams

**Description**: 
A lightweight polling tool where users can create quick polls, share them with their team, and see real-time results. Think Strawpoll but for internal teams.

**Target Users**: Small teams (5-20 people) who need quick decision-making

**Key Problems**: 
- Email threads for simple yes/no questions are slow
- Existing tools (Slack polls, etc.) lack persistence
- Need something dead simple with no setup

---

## Expected Lean Mode Output

### Step 1: Requirements (~10 min)
**Expected Artifacts**:
- Feature catalog: 5-7 Must-Have features (create poll, vote, view results, share link, basic auth)
- 3-5 user stories
- Basic NFRs (page load < 2s, HTTPS, 100 concurrent users)

**Success Criteria**: 
- ‚úÖ Output is concise (< 2 pages)
- ‚úÖ Focuses only on MVP features
- ‚úÖ No extensive compliance requirements

---

### Step 2: Architecture (~15 min)
**Expected Artifacts**:
- C4 Level 1 diagram (QuickPoll app + external auth provider)
- Simple API endpoint list (5-10 endpoints)
- 2-3 database tables (users, polls, votes)

**Success Criteria**:
- ‚úÖ No C4 Level 2-3 diagrams
- ‚úÖ No detailed OpenAPI spec
- ‚úÖ Simple tech stack (e.g., Next.js + Supabase)

---

### Step 3: Security (~10 min)
**Expected Artifacts**:
- AuthN/AuthZ strategy (OAuth or email/password)
- Basic encryption (HTTPS, password hashing)
- Input validation checklist

**Success Criteria**:
- ‚úÖ No full STRIDE tables
- ‚úÖ No SOC2/HIPAA compliance mapping
- ‚úÖ Practical security only

---

### Step 4: Testing (~10 min)
**Expected Artifacts**:
- Unit test strategy (5-10 key functions)
- Integration test strategy (all API endpoints)
- Manual testing checklist (5-10 flows)

**Success Criteria**:
- ‚úÖ No E2E tests
- ‚úÖ No performance/security testing
- ‚úÖ 70% coverage goal (not 100%)

---

### Step 5: Implementation Plan (~10 min)
**Expected Artifacts**:
- 3 phases (Foundation, Core Features, Polish)
- 10-15 tasks with time estimates
- Simple dependency graph

**Success Criteria**:
- ‚úÖ Tasks are 2-8 hours each
- ‚úÖ Focus on Must-Have features only
- ‚úÖ Total MVP timeline: 2-3 weeks

---

## Validation Checklist

### Prompt Quality
- [ ] Prompts are clear and easy to follow
- [ ] Examples are helpful and relevant
- [ ] Instructions are concise (not walls of text)
- [ ] Output format is well-defined

### Workflow Efficiency
- [ ] Total time to complete all 5 steps: ~1 hour
- [ ] Each step builds on the previous one
- [ ] No redundant information requested
- [ ] Easy to copy-paste between steps

### Output Quality
- [ ] Artifacts are actionable (can start building immediately)
- [ ] No over-engineering (appropriate for MVP)
- [ ] Consistent naming and structure
- [ ] Clear enough for an AI agent to implement

---

## Next Steps After Validation

If test passes:
1. ‚úÖ Lean mode is ready for use
2. Continue with Phase 2 (Modular Prompts)
3. Add GUIDE.md mode selector

If test fails:
1. Identify issues in prompts
2. Refine unclear sections
3. Re-test before proceeding

```

## File: prompts/modules/README.md
```md
# Modular Prompt Architecture Guide

## Overview
Instead of using monolithic prompts (like `01_requirements_analysis.md`), you can compose custom workflows using **prompt modules**.

## Why Modular?
- **Shorter prompts** = fewer LLM hallucinations
- **Easier to maintain** = update one module, not entire prompt
- **Flexible** = mix and match modules for your needs
- **Robust** = smaller prompts are more reliable

## How to Use

### Option 1: Use Pre-Composed Prompts (Recommended)
Just use the existing prompts:
- `prompts/01_requirements_analysis.md` (uses all requirements modules)
- `prompts/02_architecture_design.md` (uses all architecture modules)
- etc.

### Option 2: Compose Your Own
Pick and choose modules based on your needs:

**Example: Lightweight Requirements**
```
Use modules:
- prompts/modules/requirements/product_overview.md
- prompts/modules/requirements/feature_catalog.md
- prompts/modules/requirements/user_stories.md

Skip:
- Functional requirements table
- Non-functional requirements
```

**Example: Security-Focused Architecture**
```
Use modules:
- prompts/modules/architecture/c4_diagrams.md
- prompts/modules/architecture/data_models.md
- prompts/modules/security/threat_modeling.md
- prompts/modules/security/authz.md

Skip:
- API design
- Technology stack
```

## Module Directory Structure

```
prompts/modules/
‚îú‚îÄ‚îÄ requirements/
‚îÇ   ‚îú‚îÄ‚îÄ product_overview.md
‚îÇ   ‚îú‚îÄ‚îÄ feature_catalog.md
‚îÇ   ‚îú‚îÄ‚îÄ functional_requirements.md
‚îÇ   ‚îú‚îÄ‚îÄ nonfunctional_requirements.md
‚îÇ   ‚îî‚îÄ‚îÄ user_stories.md
‚îú‚îÄ‚îÄ architecture/
‚îÇ   ‚îú‚îÄ‚îÄ c4_diagrams.md
‚îÇ   ‚îú‚îÄ‚îÄ technology_stack.md
‚îÇ   ‚îú‚îÄ‚îÄ api_design.md
‚îÇ   ‚îî‚îÄ‚îÄ data_models.md
‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îú‚îÄ‚îÄ threat_modeling.md
‚îÇ   ‚îú‚îÄ‚îÄ authz.md
‚îÇ   ‚îî‚îÄ‚îÄ compliance.md
‚îî‚îÄ‚îÄ testing/
    ‚îú‚îÄ‚îÄ test_pyramid.md
    ‚îú‚îÄ‚îÄ performance_testing.md
    ‚îî‚îÄ‚îÄ security_testing.md
```

## Module Format

Each module is self-contained and follows this structure:

```markdown
# [Module Name]

## Purpose
[What this module generates]

## Input Required
[What context the LLM needs]

## Output Format
[Exact structure to generate]

## Example
[Sample output]
```

## Composing Modules

### Method 1: Sequential (Recommended)
Run modules one at a time, feeding output to the next:

1. Run `product_overview.md` ‚Üí save output
2. Run `feature_catalog.md` + attach previous output ‚Üí save
3. Run `user_stories.md` + attach all previous outputs ‚Üí save

### Method 2: Single Prompt
Combine multiple modules into one prompt:

```
I need you to generate:
1. [Copy content from product_overview.md]
2. [Copy content from feature_catalog.md]
3. [Copy content from user_stories.md]
```

**Warning**: This defeats the purpose of modularity. Only use for 2-3 small modules.

## Benefits by Use Case

### Solo Developer (MVP)
**Use**: 3-5 modules only
- Product overview
- Feature catalog (Must-Have only)
- User stories (top 3)
- C4 Level 1
- Data models

**Skip**: Everything else

### Small Team (Production)
**Use**: 8-12 modules
- All requirements modules
- C4 Level 1-2
- API design
- Data models
- Basic threat modeling
- Test pyramid

**Skip**: Compliance, detailed security

### Enterprise Team
**Use**: All modules (15+)
- Full requirements
- C4 Level 1-3
- Full security (STRIDE, compliance)
- Full testing (pyramid + perf + security)

## Migration Guide

### From Monolithic to Modular

**Before** (Monolithic):
```bash
# Copy entire 01_requirements_analysis.md
# Paste to LLM
# Get 5-page output
```

**After** (Modular):
```bash
# Copy product_overview.md
# Paste to LLM ‚Üí get 1 paragraph

# Copy feature_catalog.md
# Paste to LLM + attach overview ‚Üí get feature list

# Copy user_stories.md
# Paste to LLM + attach features ‚Üí get stories
```

**Result**: Same output, but in 3 focused steps instead of 1 giant prompt.

## Tips

1. **Start small**: Use 2-3 modules first, add more as needed
2. **Feed forward**: Always attach previous outputs as context
3. **Iterate**: If output is wrong, re-run just that module
4. **Combine for speed**: If modules are small (<500 words), combine 2-3

## Next Steps

1. Browse `prompts/modules/` to see available modules
2. Pick modules for your use case
3. Run them sequentially
4. Combine outputs into final document

```

## File: prompts/modules/architecture/c4_diagrams.md
```md
# C4 Diagrams Module

## Purpose
Generate C4 architecture diagrams (System Context, Container, Component).

## Input Required
- Product overview
- Feature catalog
- OR brief product description

## Output Format

```markdown
## C4 Architecture Diagrams

### Level 1: System Context
\`\`\`mermaid
C4Context
    title System Context - [Product Name]
    
    Person(user, "[User Type]", "Description")
    System(app, "[Product Name]", "Core application")
    System_Ext(external, "[External System]", "Description")
    
    Rel(user, app, "Uses")
    Rel(app, external, "Integrates with")
\`\`\`

### Level 2: Container Diagram
\`\`\`mermaid
C4Container
    title Container Diagram - [Product Name]
    
    Person(user, "[User Type]")
    
    Container(web, "Web Application", "React", "User interface")
    Container(api, "API", "Node.js", "Business logic")
    ContainerDb(db, "Database", "PostgreSQL", "Data storage")
    
    Rel(user, web, "Uses", "HTTPS")
    Rel(web, api, "Calls", "REST/JSON")
    Rel(api, db, "Reads/Writes", "SQL")
\`\`\`

### Level 3: Component Diagram (Optional)
[Only for complex systems]
```

## Instructions for LLM

1. **Level 1** (Required): Show the system and its external dependencies
2. **Level 2** (Required): Show internal containers (frontend, backend, database)
3. **Level 3** (Optional): Only if system is complex (5+ containers)

Use Mermaid C4 syntax for all diagrams.

## Example Output

```markdown
## C4 Architecture Diagrams

### Level 1: System Context
\`\`\`mermaid
C4Context
    title System Context - TaskFlow
    
    Person(dev, "Developer", "Solo developer managing tasks")
    System(taskflow, "TaskFlow", "Task management application")
    System_Ext(github, "GitHub API", "Issue tracking")
    
    Rel(dev, taskflow, "Manages tasks")
    Rel(taskflow, github, "Imports issues", "REST API")
\`\`\`

### Level 2: Container Diagram
\`\`\`mermaid
C4Container
    title Container Diagram - TaskFlow
    
    Person(dev, "Developer")
    
    Container(spa, "Single Page App", "React", "Task board UI")
    Container(api, "API Server", "Node.js/Express", "Business logic")
    ContainerDb(db, "Database", "PostgreSQL", "Task storage")
    System_Ext(github, "GitHub API")
    
    Rel(dev, spa, "Uses", "HTTPS")
    Rel(spa, api, "API calls", "REST/JSON")
    Rel(api, db, "Reads/Writes", "SQL")
    Rel(api, github, "Fetches issues", "REST API")
\`\`\`
```

## Ready?

Paste the product overview and feature catalog below, and I'll generate the C4 diagrams.

```

## File: prompts/modules/architecture/data_models.md
```md
# Data Models Module

## Purpose
Generate database schema with tables, columns, and relationships.

## Input Required
- Feature catalog
- User stories
- OR brief product description

## Output Format

```markdown
## Data Models

### Table: [table_name]
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PRIMARY KEY |
| [column] | [type] | [constraints] |
...

**Indexes**:
- `idx_[table]_[column]` on `[column]`

---

### Table: [table_name]
...

## Relationships

\`\`\`mermaid
erDiagram
    TABLE1 ||--o{ TABLE2 : "relationship"
    TABLE2 }o--|| TABLE3 : "relationship"
\`\`\`

**Relationship Details**:
- `table1.id` ‚Üí `table2.table1_id` (one-to-many)
- `table2.table3_id` ‚Üí `table3.id` (many-to-one)
```

## Instructions for LLM

1. Define all tables needed for Must-Have features
2. Include primary keys, foreign keys, and essential indexes
3. Use standard SQL types (UUID, VARCHAR, INTEGER, TIMESTAMP, etc.)
4. Show relationships in both diagram and text

## Example Output

```markdown
## Data Models

### Table: users
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PRIMARY KEY |
| email | VARCHAR(255) | UNIQUE, NOT NULL |
| password_hash | VARCHAR(255) | NOT NULL |
| created_at | TIMESTAMP | DEFAULT NOW() |
| updated_at | TIMESTAMP | DEFAULT NOW() |

**Indexes**:
- `idx_users_email` on `email`

---

### Table: tasks
| Column | Type | Constraints |
|--------|------|-------------|
| id | UUID | PRIMARY KEY |
| user_id | UUID | FOREIGN KEY (users.id), NOT NULL |
| title | VARCHAR(255) | NOT NULL |
| description | TEXT | |
| status | VARCHAR(50) | CHECK (status IN ('todo', 'in_progress', 'done')) |
| position | INTEGER | NOT NULL |
| created_at | TIMESTAMP | DEFAULT NOW() |
| updated_at | TIMESTAMP | DEFAULT NOW() |

**Indexes**:
- `idx_tasks_user_id` on `user_id`
- `idx_tasks_status` on `status`

## Relationships

\`\`\`mermaid
erDiagram
    users ||--o{ tasks : "owns"
\`\`\`

**Relationship Details**:
- `users.id` ‚Üí `tasks.user_id` (one-to-many): A user can have many tasks
```

## Ready?

Paste the feature catalog and user stories below, and I'll generate the data models.

```

## File: prompts/modules/requirements/feature_catalog.md
```md
# Feature Catalog Module

## Purpose
Generate a prioritized list of features using MoSCoW method.

## Input Required
- Product overview (from previous module)
- OR brief product description

## Output Format

```markdown
## Feature Catalog (MoSCoW)

### Must Have (MVP Core)
1. **[Feature Name]**: [1-sentence description]
2. **[Feature Name]**: [1-sentence description]
...

### Should Have (Post-MVP)
1. **[Feature Name]**: [1-sentence description]
...

### Could Have (Future)
1. **[Feature Name]**: [1-sentence description]
...

### Won't Have (Out of Scope)
1. **[Feature Name]**: [1-sentence reason why not]
...
```

## Instructions for LLM

1. **Must Have**: 5-10 features that are absolutely required for MVP
2. **Should Have**: 5-8 features that would be nice for v1.1
3. **Could Have**: 3-5 features for future consideration
4. **Won't Have**: 2-3 features explicitly out of scope

Keep each description to ONE sentence.

## Example Output

```markdown
## Feature Catalog (MoSCoW)

### Must Have (MVP Core)
1. **Task Board**: Kanban-style board with To Do, In Progress, Done columns
2. **Create Tasks**: Add tasks with title and markdown description
3. **Drag & Drop**: Move tasks between columns with drag-and-drop
4. **Local Storage**: Save tasks in browser (no backend required)
5. **GitHub Import**: One-click import of GitHub issues as tasks

### Should Have (Post-MVP)
1. **Tags & Filters**: Organize and filter tasks by custom tags
2. **Due Dates**: Set and track task deadlines
3. **Cloud Sync**: Save tasks to backend for multi-device access
4. **Keyboard Shortcuts**: Power-user shortcuts for common actions

### Could Have (Future)
1. **Time Tracking**: Track time spent on each task
2. **Subtasks**: Break down tasks into smaller subtasks
3. **Team Collaboration**: Share boards with team members

### Won't Have (Out of Scope)
1. **Gantt Charts**: Too complex for the target audience
2. **Resource Management**: Not needed for solo developers
3. **Billing/Invoicing**: Out of scope for a task management tool
```

## Ready?

Paste the product overview (or idea) below, and I'll generate the feature catalog.

```

## File: prompts/modules/requirements/product_overview.md
```md
# Product Overview Module

## Purpose
Generate a concise executive summary of the product idea.

## Input Required
- Brief description of the product idea
- Target users (if known)
- Problem being solved

## Output Format

```markdown
## Product Overview

**Name**: [Product Name]
**Tagline**: [One-sentence value proposition]

**The Problem**: [2-3 sentences describing the pain point]

**The Solution**: [2-3 sentences describing how the product solves it]

**Target Audience**:
- **Primary**: [Main user persona]
- **Secondary**: [Additional user personas]
```

## Instructions for LLM

1. Keep the product name short and memorable
2. Tagline should be under 10 words
3. Problem and Solution should each be 2-3 sentences max
4. Identify 1 primary and 1-2 secondary personas

## Example Output

```markdown
## Product Overview

**Name**: TaskFlow
**Tagline**: Simple task management for solo developers

**The Problem**: Developers need a lightweight way to track tasks without the complexity of enterprise project management tools. Existing solutions like Jira are overkill for solo projects, while simple to-do apps lack developer-specific features like GitHub integration and markdown support.

**The Solution**: TaskFlow provides a minimal Kanban board with drag-and-drop, markdown task descriptions, and one-click GitHub issue import. It's designed for developers who want just enough structure without the overhead.

**Target Audience**:
- **Primary**: Solo developers and freelancers managing personal projects
- **Secondary**: Small development teams (2-5 people) working on side projects
```

## Ready?

Paste the product idea below, and I'll generate the product overview.

```

## File: prompts/modules/requirements/user_stories.md
```md
# User Stories Module

## Purpose
Generate user stories with acceptance criteria for Must-Have features.

## Input Required
- Feature catalog (from previous module)
- OR list of Must-Have features

## Output Format

```markdown
## User Stories

### US-001: [Story Title]
**As a** [user type]
**I want** [action]
**So that** [benefit]

**Acceptance Criteria**:
- [ ] [Specific, testable criterion]
- [ ] [Specific, testable criterion]
- [ ] [Specific, testable criterion]

---

### US-002: [Story Title]
...
```

## Instructions for LLM

1. Create **1 user story per Must-Have feature**
2. Each story should have **3-5 acceptance criteria**
3. Acceptance criteria must be **specific and testable**
4. Use checkboxes for acceptance criteria

## Example Output

```markdown
## User Stories

### US-001: Create a Task
**As a** developer
**I want** to create a task with a title and markdown description
**So that** I can track what I need to do

**Acceptance Criteria**:
- [ ] User can click "New Task" button
- [ ] User can enter a task title (required field)
- [ ] User can enter a markdown description (optional field)
- [ ] Task appears in "To Do" column after creation
- [ ] Task has a unique ID and timestamp

---

### US-002: Move Tasks Between Columns
**As a** developer
**I want** to drag tasks between columns
**So that** I can update task status visually

**Acceptance Criteria**:
- [ ] User can click and drag a task card
- [ ] Task can be dropped into any column
- [ ] Task position updates immediately (no page refresh)
- [ ] Changes persist in local storage
- [ ] Dragging is smooth and responsive (< 100ms)

---

### US-003: Import GitHub Issues
**As a** developer
**I want** to import issues from my GitHub repo
**So that** I don't have to manually recreate tasks

**Acceptance Criteria**:
- [ ] User can enter a GitHub repo URL
- [ ] System validates the URL format
- [ ] System fetches open issues via GitHub API
- [ ] Issues appear as tasks in "To Do" column
- [ ] Issue title and description are preserved
```

## Ready?

Paste the feature catalog (or Must-Have features) below, and I'll generate the user stories.

```

## File: prompts/modules/security/threat_modeling.md
```md
# Threat Modeling Module

## Purpose
Generate a STRIDE threat model for the application.

## Input Required
- C4 diagrams
- Data models
- Feature catalog

## Output Format

```markdown
## Threat Model (STRIDE)

### Spoofing
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| [Threat description] | [How attacker could exploit] | [How we prevent it] |

### Tampering
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
...

### Repudiation
...

### Information Disclosure
...

### Denial of Service
...

### Elevation of Privilege
...

## High-Priority Threats

1. **[Threat Name]** (Severity: High)
   - **Risk**: [Description]
   - **Mitigation**: [Action plan]
```

## Instructions for LLM

1. Identify 2-3 threats per STRIDE category
2. Focus on realistic, high-impact threats
3. Provide specific mitigations (not generic advice)
4. Highlight top 3-5 high-priority threats

## Example Output

```markdown
## Threat Model (STRIDE)

### Spoofing
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| User impersonation | Attacker steals session token | Use HTTP-only cookies, short session timeouts (15 min) |
| GitHub OAuth bypass | Attacker forges OAuth callback | Validate state parameter, verify token with GitHub |

### Tampering
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| Task data modification | Attacker modifies task via API | Validate user owns task before update, use CSRF tokens |
| SQL injection | Attacker injects SQL via task title | Use parameterized queries, input validation |

### Repudiation
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| Deny task deletion | User claims they didn't delete task | Log all delete operations with user ID and timestamp |

### Information Disclosure
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| Expose other users' tasks | Attacker guesses task IDs | Use UUIDs, enforce user ownership checks |
| Leak GitHub tokens | Token exposed in logs or errors | Never log tokens, use environment variables |

### Denial of Service
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| API rate limiting bypass | Attacker floods API with requests | Implement rate limiting (100 req/min per IP) |
| Database overload | Attacker creates millions of tasks | Limit tasks per user (1000 max) |

### Elevation of Privilege
| Threat | Attack Vector | Mitigation |
|--------|---------------|------------|
| Access admin endpoints | Attacker guesses admin routes | No admin routes in MVP, use role-based access later |

## High-Priority Threats

1. **SQL Injection** (Severity: High)
   - **Risk**: Attacker could read/modify all database data
   - **Mitigation**: Use ORM (Prisma) with parameterized queries, validate all inputs

2. **Session Hijacking** (Severity: High)
   - **Risk**: Attacker steals session token and impersonates user
   - **Mitigation**: HTTP-only cookies, HTTPS only, 15-minute session timeout

3. **Unauthorized Task Access** (Severity: Medium)
   - **Risk**: User A could view/modify User B's tasks
   - **Mitigation**: Enforce user ownership checks on all task operations
```

## Ready?

Paste the C4 diagrams, data models, and feature catalog below, and I'll generate the threat model.

```

## File: prompts/modules/testing/test_pyramid.md
```md
# Test Pyramid Module

## Purpose
Generate a test strategy following the test pyramid pattern.

## Input Required
- Feature catalog
- Data models
- API endpoints (if available)

## Output Format

```markdown
## Test Strategy (Test Pyramid)

### Unit Tests (70% of tests)
**What to Test**:
- Business logic functions
- Utility functions
- Data validation

**Example Test Cases**:
- `validateEmail()`: Valid email ‚Üí true, Invalid email ‚Üí false
- `calculateTaskPosition()`: Returns correct position based on column

**Coverage Goal**: 80% of business logic

---

### Integration Tests (20% of tests)
**What to Test**:
- API endpoints
- Database operations
- External service integrations

**Example Test Cases**:
- `POST /api/tasks`: Creates task and returns 201
- `GET /api/tasks`: Returns user's tasks only
- GitHub API integration: Fetches issues successfully

**Coverage Goal**: All API endpoints

---

### E2E Tests (10% of tests)
**What to Test**:
- Critical user flows
- Multi-step interactions

**Example Test Cases**:
- User signup ‚Üí login ‚Üí create task ‚Üí drag task ‚Üí logout
- Import GitHub issues ‚Üí verify tasks appear ‚Üí delete tasks

**Coverage Goal**: Top 3-5 user flows
```

## Instructions for LLM

1. Follow the 70/20/10 ratio (Unit/Integration/E2E)
2. Provide 3-5 example test cases per level
3. Focus on Must-Have features
4. Keep coverage goals realistic

## Example Output

```markdown
## Test Strategy (Test Pyramid)

### Unit Tests (70% of tests)
**What to Test**:
- Task validation logic
- Position calculation
- Status transitions
- Input sanitization

**Example Test Cases**:
- `validateTaskTitle()`: 
  - Valid title (1-255 chars) ‚Üí true
  - Empty title ‚Üí false
  - Title > 255 chars ‚Üí false
- `calculateTaskPosition()`:
  - First task in column ‚Üí position = 0
  - Task between two others ‚Üí position = average
- `sanitizeMarkdown()`:
  - Removes script tags
  - Preserves safe markdown

**Coverage Goal**: 80% of business logic

---

### Integration Tests (20% of tests)
**What to Test**:
- Task CRUD API endpoints
- User authentication
- GitHub API integration
- Database transactions

**Example Test Cases**:
- `POST /api/tasks`:
  - Valid request ‚Üí 201 Created
  - Missing title ‚Üí 400 Bad Request
  - Unauthorized ‚Üí 401 Unauthorized
- `GET /api/tasks`:
  - Returns only current user's tasks
  - Filters by status if provided
  - Returns empty array if no tasks
- `POST /api/github/import`:
  - Valid repo ‚Üí imports issues
  - Invalid repo ‚Üí 404 Not Found
  - Rate limit exceeded ‚Üí 429 Too Many Requests

**Coverage Goal**: All API endpoints

---

### E2E Tests (10% of tests)
**What to Test**:
- Complete user journeys
- Cross-browser compatibility
- Mobile responsiveness

**Example Test Cases**:
- **Happy Path**: 
  - User signs up ‚Üí verifies email ‚Üí logs in ‚Üí creates task ‚Üí drags to "Done" ‚Üí logs out
- **GitHub Import Flow**:
  - User connects GitHub ‚Üí selects repo ‚Üí imports issues ‚Üí verifies tasks created
- **Error Handling**:
  - User loses connection mid-drag ‚Üí task reverts ‚Üí error message shown

**Coverage Goal**: Top 5 user flows

## Test Tools

- **Unit**: Jest, Vitest
- **Integration**: Supertest, Playwright
- **E2E**: Playwright, Cypress
```

## Ready?

Paste the feature catalog and data models below, and I'll generate the test strategy.

```

